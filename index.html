

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Ignite Simple &mdash; ignite-simple 0.0.1 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script type="text/javascript" src="_static/jquery.js"></script>
        <script type="text/javascript" src="_static/underscore.js"></script>
        <script type="text/javascript" src="_static/doctools.js"></script>
        <script type="text/javascript" src="_static/language_data.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="#" class="icon icon-home"> ignite-simple
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <!-- Local TOC -->
              <div class="local-toc"><ul>
<li><a class="reference internal" href="#">Ignite Simple</a></li>
<li><a class="reference internal" href="#module-ignite_simple.analarams">ignite_simple.analarams</a></li>
<li><a class="reference internal" href="#module-ignite_simple.hyperparams">ignite_simple.hyperparams</a></li>
<li><a class="reference internal" href="#module-ignite_simple.model_manager">ignite_simple.model_manager</a></li>
<li><a class="reference internal" href="#module-ignite_simple.trainer">ignite_simple.trainer</a></li>
<li><a class="reference internal" href="#module-ignite_simple.analysis">ignite_simple.analysis</a></li>
<li><a class="reference internal" href="#module-ignite_simple.text_analysis">ignite_simple.text_analysis</a></li>
<li><a class="reference internal" href="#module-ignite_simple.range_finder">ignite_simple.range_finder</a></li>
<li><a class="reference internal" href="#module-ignite_simple.tuner">ignite_simple.tuner</a></li>
<li><a class="reference internal" href="#module-ignite_simple.helper">ignite_simple.helper</a></li>
<li><a class="reference internal" href="#module-ignite_simple.utils">ignite_simple.utils</a></li>
<li><a class="reference internal" href="#module-ignite_simple.figure_utils">ignite_simple.figure_utils</a></li>
<li><a class="reference internal" href="#module-ignite_simple.vary_bs_loader">ignite_simple.vary_bs_loader</a></li>
<li><a class="reference internal" href="#module-ignite_simple.dispatcher">ignite_simple.dispatcher</a></li>
<li><a class="reference internal" href="#indices-and-tables">Indices and tables</a></li>
</ul>
</div>
            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="#">ignite-simple</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="#">Docs</a> &raquo;</li>
        
      <li>Ignite Simple</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/index.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="ignite-simple">
<h1>Ignite Simple<a class="headerlink" href="#ignite-simple" title="Permalink to this headline">¶</a></h1>
<div class="toctree-wrapper compound">
</div>
</div>
<div class="section" id="module-ignite_simple.analarams">
<span id="ignite-simple-analarams"></span><h1>ignite_simple.analarams<a class="headerlink" href="#module-ignite_simple.analarams" title="Permalink to this headline">¶</a></h1>
<p>Describes parameters relevant for analysis. The parameters are specified
for the output, and what’s required to produce that output is calculated from
that.</p>
<dl class="class">
<dt id="ignite_simple.analarams.AnalysisSettings">
<em class="property">class </em><code class="sig-prename descclassname">ignite_simple.analarams.</code><code class="sig-name descname">AnalysisSettings</code><span class="sig-paren">(</span><em class="sig-param">hparam_selection_specifics: bool</em>, <em class="sig-param">hparam_selection_specific_imgs: bool</em>, <em class="sig-param">training_metric_imgs: bool</em>, <em class="sig-param">typical_run_pca3dvis: bool</em>, <em class="sig-param">typical_run_pca3dvis_draft: bool</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ignite_simple/analarams.html#AnalysisSettings"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite_simple.analarams.AnalysisSettings" title="Permalink to this definition">¶</a></dt>
<dd><p>Describes the analysis settings. Note that, where relevant and
equivalent, parallel computations are described as if they were
performed sequentially.</p>
<dl class="field-list simple">
<dt class="field-odd">Variables</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hparam_selection_specifics</strong> (<em>bool</em>) – True if the output should include
a text explanation about how specifically we came about selecting the
learning rate and batch size, by going through the numbers, False
otherwise.</p></li>
<li><p><strong>hparam_selection_specific_imgs</strong> (<em>bool</em>) – True if the output should
include figures with captions for the hyper paramater selection process
as it occurred for this model specifically, False otherwise.</p></li>
<li><p><strong>training_metric_imgs</strong> (<em>bool</em>) – True if the output should include figures
with captions for the performance of the model through training, i.e.,
accuracy vs epoch and loss vs epoch figures.</p></li>
<li><p><strong>typical_run_pca3dvis</strong> (<em>bool</em>) – True if the output should include a video
from pca3dvis for the points as they moved through the network, False
otherwise.</p></li>
<li><p><strong>typical_run_pca3dvis_draft</strong> (<em>bool</em>) – If <cite>typical_run_pca3dvis</cite> is True,
then the value of <cite>typical_run_pca3dvis_draft</cite> corresponds to if the
video should have draft settings. If <cite>typical_run_pca3dvis</cite> is False,
this has no effect.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="ignite_simple.analarams.animations">
<code class="sig-prename descclassname">ignite_simple.analarams.</code><code class="sig-name descname">animations</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; ignite_simple.analarams.AnalysisSettings<a class="reference internal" href="_modules/ignite_simple/analarams.html#animations"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite_simple.analarams.animations" title="Permalink to this definition">¶</a></dt>
<dd><p>Analysis output that uses text, images, and animations. Animations are
videos which are under 15 seconds for the purpose of this module.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>the animations preset for analysis settings, which produces text,
images, and animations in the output.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="#ignite_simple.analarams.AnalysisSettings" title="ignite_simple.analarams.AnalysisSettings">AnalysisSettings</a></p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="ignite_simple.analarams.animations_draft">
<code class="sig-prename descclassname">ignite_simple.analarams.</code><code class="sig-name descname">animations_draft</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; ignite_simple.analarams.AnalysisSettings<a class="reference internal" href="_modules/ignite_simple/analarams.html#animations_draft"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite_simple.analarams.animations_draft" title="Permalink to this definition">¶</a></dt>
<dd><p>Analysis output that uses text, images, and animations but the
animations are given draft settings (i.e. low-fps and low resolution)
to speed up output. For the purposes of this module, animations are
simply videos under 15 seconds.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>the animations-draft preset for analysis settings, which produces
text, image, and draft-quality animations in the output.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="#ignite_simple.analarams.AnalysisSettings" title="ignite_simple.analarams.AnalysisSettings">AnalysisSettings</a></p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="ignite_simple.analarams.get_settings">
<code class="sig-prename descclassname">ignite_simple.analarams.</code><code class="sig-name descname">get_settings</code><span class="sig-paren">(</span><em class="sig-param">preset: Union[str, ignite_simple.analarams.AnalysisSettings]</em><span class="sig-paren">)</span> &#x2192; ignite_simple.analarams.AnalysisSettings<a class="reference internal" href="_modules/ignite_simple/analarams.html#get_settings"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite_simple.analarams.get_settings" title="Permalink to this definition">¶</a></dt>
<dd><p>Gets the analysis settings from the given preset name or analysis
settings.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>preset</strong> – either a str name of a preset or the settings to return</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>the corresponding preset or just the argument if its already
AnalysisSettings</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="ignite_simple.analarams.images">
<code class="sig-prename descclassname">ignite_simple.analarams.</code><code class="sig-name descname">images</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; ignite_simple.analarams.AnalysisSettings<a class="reference internal" href="_modules/ignite_simple/analarams.html#images"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite_simple.analarams.images" title="Permalink to this definition">¶</a></dt>
<dd><p>Analysis output that uses text and images only</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>the images preset for analysis settings, which produces text
and image output.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="#ignite_simple.analarams.AnalysisSettings" title="ignite_simple.analarams.AnalysisSettings">AnalysisSettings</a></p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="ignite_simple.analarams.none">
<code class="sig-prename descclassname">ignite_simple.analarams.</code><code class="sig-name descname">none</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; ignite_simple.analarams.AnalysisSettings<a class="reference internal" href="_modules/ignite_simple/analarams.html#none"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite_simple.analarams.none" title="Permalink to this definition">¶</a></dt>
<dd><p>Analysis settings that produce absolutely nothing</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>the none preset for analysis settings, which produces no output</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="#ignite_simple.analarams.AnalysisSettings" title="ignite_simple.analarams.AnalysisSettings">AnalysisSettings</a></p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="ignite_simple.analarams.text">
<code class="sig-prename descclassname">ignite_simple.analarams.</code><code class="sig-name descname">text</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; ignite_simple.analarams.AnalysisSettings<a class="reference internal" href="_modules/ignite_simple/analarams.html#text"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite_simple.analarams.text" title="Permalink to this definition">¶</a></dt>
<dd><p>Analysis output that uses text only</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>the text preset for analysis settings, which produces text
output.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="#ignite_simple.analarams.AnalysisSettings" title="ignite_simple.analarams.AnalysisSettings">AnalysisSettings</a></p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="ignite_simple.analarams.video">
<code class="sig-prename descclassname">ignite_simple.analarams.</code><code class="sig-name descname">video</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; ignite_simple.analarams.AnalysisSettings<a class="reference internal" href="_modules/ignite_simple/analarams.html#video"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite_simple.analarams.video" title="Permalink to this definition">¶</a></dt>
<dd><p>Analysis output that uses text, images, animations, and video</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>the video preset for analysis settings, which produces text,
images, animations, and videos in the output.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="#ignite_simple.analarams.AnalysisSettings" title="ignite_simple.analarams.AnalysisSettings">AnalysisSettings</a></p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="ignite_simple.analarams.video_draft">
<code class="sig-prename descclassname">ignite_simple.analarams.</code><code class="sig-name descname">video_draft</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; ignite_simple.analarams.AnalysisSettings<a class="reference internal" href="_modules/ignite_simple/analarams.html#video_draft"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite_simple.analarams.video_draft" title="Permalink to this definition">¶</a></dt>
<dd><p>Analysis output that uses text, images, animations, and video but the
animations and video(s) are given draft settings (i.e. low-fps and
low-resolution) to speed up output</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>the video-draft preset for analysis settings, which produces
text, images, draft-quality animations, and draft-quality videos in the
output.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="#ignite_simple.analarams.AnalysisSettings" title="ignite_simple.analarams.AnalysisSettings">AnalysisSettings</a></p>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-ignite_simple.hyperparams">
<span id="ignite-simple-hyperparams"></span><h1>ignite_simple.hyperparams<a class="headerlink" href="#module-ignite_simple.hyperparams" title="Permalink to this headline">¶</a></h1>
<p>This module is used to describe the hyperparameter tuning settings and
presets used for training.</p>
<dl class="class">
<dt id="ignite_simple.hyperparams.HyperparameterSettings">
<em class="property">class </em><code class="sig-prename descclassname">ignite_simple.hyperparams.</code><code class="sig-name descname">HyperparameterSettings</code><span class="sig-paren">(</span><em class="sig-param">lr_start: float</em>, <em class="sig-param">lr_end: float</em>, <em class="sig-param">lr_min_inits: int</em>, <em class="sig-param">batch_start: int</em>, <em class="sig-param">batch_end: int</em>, <em class="sig-param">batch_rn_min_inits: int</em>, <em class="sig-param">batch_pts: int</em>, <em class="sig-param">batch_pt_min_inits: int</em>, <em class="sig-param">rescan_lr_after_bs: bool</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ignite_simple/hyperparams.html#HyperparameterSettings"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite_simple.hyperparams.HyperparameterSettings" title="Permalink to this definition">¶</a></dt>
<dd><p>Describes settings for tuning hyperparameters</p>
<dl class="field-list simple">
<dt class="field-odd">Variables</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lr_start</strong> (<em>float</em>) – the smallest learning rate that is checked</p></li>
<li><p><strong>lr_end</strong> (<em>float</em>) – the largest learning rate that is checked</p></li>
<li><p><strong>lr_min_inits</strong> (<em>int</em>) – the minimum number of model initializations that
are averaged together and then smoothed to get the lr-vs-accuracy plot.
Note that when multiple physical cores are available they will be
utilized since this process is well-suited to parallelization</p></li>
<li><p><strong>batch_start</strong> (<em>int</em>) – the smallest batch size that is checked during the
initial reasonableness sweep (a single pass)</p></li>
<li><p><strong>batch_end</strong> (<em>int</em>) – the largest batch size that is checked during the
initial reasonableness sweep (a single pass)</p></li>
<li><p><strong>batch_rn_min_inits</strong> (<em>int</em>) – the minimum number of model initializations
that are averaged together then smoothed to get the batch-vs-accuracy
plot.</p></li>
<li><p><strong>batch_pts</strong> (<em>int</em>) – the number of different batch sizes which are checked,
points sampled from a distribution weighted toward a higher first
derivative of performance. Must be either 0 or greater than 1. If 0, the
batch size corresponding to the greatest increase in accuracy during
the reasonableness sweep is used.</p></li>
<li><p><strong>batch_pt_min_inits</strong> (<em>int</em>) – the minimum number of model initializations
that are combined together via LogSumExp. We use LogSumExp instead of
mean because we care more about the best performance than the most
consistent performance when selecting batch size. If you want more
motivation, we prefer a final accuracy of [0, 1, 1] over 3 trials to
[2/3, 2/3, 2/3] even though the mean is the same</p></li>
<li><p><strong>rescan_lr_after_bs</strong> (<em>bool</em>) – if True, the learning rate is scanned once
more after we tweak the batch size. otherwise, we use the same ratio
of learning rate to batch size as we found in the first sweep.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="ignite_simple.hyperparams.fast">
<code class="sig-prename descclassname">ignite_simple.hyperparams.</code><code class="sig-name descname">fast</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; ignite_simple.hyperparams.HyperparameterSettings<a class="reference internal" href="_modules/ignite_simple/hyperparams.html#fast"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite_simple.hyperparams.fast" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a reasonably fast (in time spent tuning parameters) preset</p>
</dd></dl>

<dl class="function">
<dt id="ignite_simple.hyperparams.fastest">
<code class="sig-prename descclassname">ignite_simple.hyperparams.</code><code class="sig-name descname">fastest</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; ignite_simple.hyperparams.HyperparameterSettings<a class="reference internal" href="_modules/ignite_simple/hyperparams.html#fastest"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite_simple.hyperparams.fastest" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the fastest (in time spent tuning parameters) preset</p>
</dd></dl>

<dl class="function">
<dt id="ignite_simple.hyperparams.get_settings">
<code class="sig-prename descclassname">ignite_simple.hyperparams.</code><code class="sig-name descname">get_settings</code><span class="sig-paren">(</span><em class="sig-param">preset: Union[str, ignite_simple.hyperparams.HyperparameterSettings]</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ignite_simple/hyperparams.html#get_settings"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite_simple.hyperparams.get_settings" title="Permalink to this definition">¶</a></dt>
<dd><p>Gets the corresponding preset if the argument is a name of one,
returns the argument directly if the argument is already a settings
object, and raises an exception in all other circumstances.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>preset</strong> – the name for a preset or the complete settings object</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>the corresponding preset or the settings object passed in</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="ignite_simple.hyperparams.slow">
<code class="sig-prename descclassname">ignite_simple.hyperparams.</code><code class="sig-name descname">slow</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; ignite_simple.hyperparams.HyperparameterSettings<a class="reference internal" href="_modules/ignite_simple/hyperparams.html#slow"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite_simple.hyperparams.slow" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a somewhat slow (in time spent tuning parameters) preset</p>
</dd></dl>

<dl class="function">
<dt id="ignite_simple.hyperparams.slowest">
<code class="sig-prename descclassname">ignite_simple.hyperparams.</code><code class="sig-name descname">slowest</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; ignite_simple.hyperparams.HyperparameterSettings<a class="reference internal" href="_modules/ignite_simple/hyperparams.html#slowest"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite_simple.hyperparams.slowest" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the slowest (in time spent tuning parameters) preset</p>
</dd></dl>

</div>
<div class="section" id="module-ignite_simple.model_manager">
<span id="ignite-simple-model-manager"></span><h1>ignite_simple.model_manager<a class="headerlink" href="#module-ignite_simple.model_manager" title="Permalink to this headline">¶</a></h1>
<p>This module is meant to be responsible for all of the training performed
on an identical model, dataset, and loss. Specifically, it decides on the
folder structure, collates results for analysis, and handles archiving
old data.</p>
<dl class="function">
<dt id="ignite_simple.model_manager.train">
<code class="sig-prename descclassname">ignite_simple.model_manager.</code><code class="sig-name descname">train</code><span class="sig-paren">(</span><em class="sig-param">model_loader: Tuple[str, str, tuple, dict], dataset_loader: Tuple[str, str, tuple, dict], loss_loader: Tuple[str, str, tuple, dict], folder: str, hyperparameters: Union[str, ignite_simple.hyperparams.HyperparameterSettings], analysis: Union[str, ignite_simple.analarams.AnalysisSettings], allow_later_analysis_up_to: Union[str, ignite_simple.analarams.AnalysisSettings], accuracy_style: str, trials: int, is_continuation: bool, history_folder: str, cores: Union[str, int], trials_strict: bool = False</em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="_modules/ignite_simple/model_manager.html#train"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite_simple.model_manager.train" title="Permalink to this definition">¶</a></dt>
<dd><p>Trains the given model on the given dataset with the given loss by
finding and saving or loading the hyperparameters with the given settings,
performing the given analysis but gathering sufficient data to later
analyze up to the specified amount.</p>
<p>The folder structure is as follows:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>folder/
    hparams/
        the result from tuner.tune
    trials/
        i/  (where i=0,1,...)
            result.json
                note that for classification tasks perf is accuracy,
                and in other tasks it is inverse loss. Note that perf
                is always available and higher is better, whereas for
                loss lower is better.

                {&#39;loss_train&#39;: float, &#39;loss_val&#39;: float,
                 &#39;perf_train&#39;: float, &#39;perf_val&#39;: float}
            model_init.pt
                the initial random initialization of the model, saved
                with torch.save
            model.pt
                the model after training, saved with torch.save
            throughtime.npz
                this is only stored if storing training_metric_imgs.

                settings:
                    shape (1,), where the values are:
                        - number of points randomly selected from the
                          corresponding dataset to calculate metrics

                epochs:
                    the partial epoch number for the samples

                losses_train:
                    the loss for the corresponding epoch, same shape as
                    epochs, for the training dataset

                losses_val:
                    the loss for the corresponding epoch, same shape as
                    epochs, for the validation dataset

                perfs_train:
                    in classification tasks this is fractional accuracy
                    in other tasks, this is inverse loss

                    the performance at the corresponding epoch, same
                    shape as epochs, for the training dataset

                perfs_val:
                    in classification tasks this is fractional accuracy
                    in other tasks, this is inverse loss

                    the performance at the corresponding epoch, same
                    shape as epochs, for the validation dataset
    results.npz
        The trials/result.json except concatenated together for easier
        loading

        final_loss_train:
            shape (trials,)

        final_loss_val:
            shape (trials,)

        final_perf_train:
            shape (trials,)

        final_perf_val:
            shape (trials,)

    throughtimes.npz
        the trials/throughtime.npz, if available, stacked for easier
        loading

        settings:
            shape (1,) the number of points used for gathering metrics
            at each sample

        epochs:
            shape (samples,) the epoch that corresponds to each sample
            during training. this is a float, since we may sample
            multiple times per epoch

        losses_train:
            shape (trials, samples)

        losses_train_smoothed:
            shape (trials, samples)

        losses_val:
            shape (trials, samples)

        losses_val_smoothed:
            shape (trials, samples)

        perfs_train:
            shape (trials, samples)

        perfs_train_smoothed:
            shape (trials, samples)

        perfs_val:
            shape (trials, samples)

        perfs_val_smoothed:
            shape (trials, samples)
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_loader</strong> – (module, attrname, args, kwargs) defines where the
callable which returns a torch.nn.Module can be found, and what
arguments to pass to the callable to get the module. The callable
should return a random initialization of the model.</p></li>
<li><p><strong>dataset_loader</strong> – (module, attrname, args, kwargs) defines where
the callable which returns (train_set, val_set) can be found, and
what arguments to pass to the callable to get the datasets</p></li>
<li><p><strong>loss_loader</strong> – (module, attrname, args, kwargs) defines where the
callable which returns the torch.nn.Module that computes a scalar
value which ought to be minimized, and what arguments to pass the
callable for the loss.</p></li>
<li><p><strong>folder</strong> – the folder where the output should be stored</p></li>
<li><p><strong>hyperparameters</strong> – the hyperparameter settings or a name of a
preset (one of <cite>fastest</cite>, <cite>fast</cite>, <cite>slow</cite>, and <cite>slowest</cite>)</p></li>
<li><p><strong>analysis</strong> – the analysis settings or a name of a preset
(typically one of <cite>none</cite>, <cite>text</cite>, <cite>images</cite>, <cite>animations</cite>, <cite>videos</cite>),
for a complete list see <cite>ignite_simple.analarams</cite>. It is always
equivalent to set this value to <cite>none</cite> and then call
analysis.reanalyze with the desired analysis</p></li>
<li><p><strong>allow_later_analysis_up_to</strong> – this is also an analysis settings or
name of a preset, except this analysis isn’t produced but instead
we ensure that sufficient data is collected to perform this analysis
if desired later. it must be at least as high as analysis</p></li>
<li><p><strong>accuracy_style</strong> – one of <cite>classification</cite>, <cite>multiclass</cite>, and
<cite>inv-loss</cite> to describe how performance is measured. classification
assumes one-hot labels for the output, multiclass assumes potentially
multiple ones in the labels, and <cite>inv-loss</cite> uses 1/loss as the
performance metric instead.</p></li>
<li><p><strong>trials</strong> – the number of trials which should be formed with the found
settings</p></li>
<li><p><strong>is_continuation</strong> – if True then if folder already exists then it is
assumed to have been the result of this function called with the same
parameters except possible trials, and the result will be the sum of
the existing trials plus the new trials to perform. If this is False
and the folder already exists, it will be moved into history_folder
where the name is the current timestamp.</p></li>
<li><p><strong>history_folder</strong> – where to store the old folders if they are found
when is_continuation is False.</p></li>
<li><p><strong>cores</strong> – either an integer for the number of physical cores that are
available for training, or the string ‘all’ for the number of cores
to be auto-detected and used.</p></li>
<li><p><strong>trials_strict</strong> – if False, then this will use all available resources
to compute trials such that this completes in approximately the minimum
amount of time to produce the required number of trials. This may
result in more than the specified number of trials being run. If True,
exactly trial runs will be performed regardless of the amount of
available computational resources (i.e., available cores may be unused)</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-ignite_simple.trainer">
<span id="ignite-simple-trainer"></span><h1>ignite_simple.trainer<a class="headerlink" href="#module-ignite_simple.trainer" title="Permalink to this headline">¶</a></h1>
<p>This module manages preparing and running the training environment for given
settings.</p>
<dl class="class">
<dt id="ignite_simple.trainer.TrainSettings">
<em class="property">class </em><code class="sig-prename descclassname">ignite_simple.trainer.</code><code class="sig-name descname">TrainSettings</code><span class="sig-paren">(</span><em class="sig-param">accuracy_style: str, model_loader: Tuple[str, str, tuple, dict], loss_loader: Tuple[str, str, tuple, dict], task_loader: Tuple[str, str, tuple, dict], handlers: Tuple[Tuple[str, Tuple[str, str, tuple, dict]]], initializer: Optional[Tuple[str, str, tuple, dict]], lr_start: float, lr_end: float, cycle_time_epochs: int, epochs: int</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ignite_simple/trainer.html#TrainSettings"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite_simple.trainer.TrainSettings" title="Permalink to this definition">¶</a></dt>
<dd><p>Describes the settings which ultimately go into a training session.
This is intended to be trivially serializable, in that all attributes are
built-ins that can be json serialized. The train function here runs in the
same process, but this strategy allows us to use the same interface design
throughout and allows repeating / printing training sessions trivially.</p>
<dl class="field-list simple">
<dt class="field-odd">Variables</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>accuracy_style</strong> (<em>str</em>) – <p>one of the following constants:</p>
<ul>
<li><dl class="simple">
<dt>classification</dt><dd><p>labels are integers which correspond to the class,
outputs are one-hot encoded classes</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>multiclass</dt><dd><p>labels are one-hot encoded multi-class labels, outputs are the same</p>
</dd>
</dl>
</li>
<li><dl>
<dt>inv-loss</dt><dd><p>accuracy is not measured and inverse loss is used as the
performance metric instead. For stability, and legibility of plots,</p>
<div class="math">
<p><img src="_images/math/54d36e66a02b3c9c7ec49ec80fae4533ce23f580.svg" alt="\frac{1}{\text{loss} + 1}"/></p>
</div><p>is used.</p>
</dd>
</dl>
</li>
</ul>
</p></li>
<li><p><strong>str</strong><strong>, </strong><strong>tuple</strong><strong>, </strong><strong>dict</strong><strong>] </strong><strong>model_loader</strong> (<em>tuple</em><em>[</em><em>str</em><em>,</em>) – the tuple contains the
module and corresponding attribute name for a function which returns
the nn.Module to train. The module must have the calling convention
<cite>model(inp) -&gt; out</cite>. The next two arguments are the args and keyword
args to the callable respectively.</p></li>
<li><p><strong>str</strong><strong>, </strong><strong>tuple</strong><strong>, </strong><strong>dict</strong><strong>] </strong><strong>loss_loader</strong> (<em>tuple</em><em>[</em><em>str</em><em>,</em>) – the tuple contains the
model and corresponding attribute name for a function which returns
the loss function to minimize.</p></li>
<li><p><strong>str</strong><strong>, </strong><strong>tuple</strong><strong>, </strong><strong>dict</strong><strong>] </strong><a class="reference internal" href="#ignite_simple.utils.task_loader" title="ignite_simple.utils.task_loader"><strong>task_loader</strong></a> (<em>tuple</em><em>[</em><em>str</em><em>,</em>) – the tuple contains the
module and corresponding attribute name for a function which returns
<code class="code docutils literal notranslate"><span class="pre">(train_set,</span> <span class="pre">val_set,</span> <span class="pre">train_loader)</span></code>, each as described in
TrainState. The next two arguments are the args and keyword args
to the callable respectively.</p></li>
<li><p><strong>tuple</strong><strong>[</strong><strong>str</strong><strong>, </strong><strong>str</strong><strong>, </strong><strong>tuple</strong><strong>, </strong><strong>dict</strong><strong>]</strong><strong>]</strong><strong>] </strong><strong>handlers</strong> (<em>tuple</em><em>[</em><em>tuple</em><em>[</em><em>str</em><em>,</em>) – <p>the event
handlers for the engine which will perform training. After the
specified positional arguments, the handlers will be passed the Engine
that is training the model and the TrainState that is in use. The str
associated with each callable is the event that each callable listens
to.</p>
</p></li>
<li><p><strong>str</strong><strong>, </strong><strong>tuple</strong><strong>, </strong><strong>dict</strong><strong>] </strong><strong>initializer</strong> (<em>tuple</em><em>[</em><em>str</em><em>,</em>) – this is called with trainer
as the next positional argument. May be used to attach additional
events to the trainer.</p></li>
<li><p><strong>lr_start</strong> (<em>float</em>) – the learning rate at the start of each cycle</p></li>
<li><p><strong>lr_end</strong> (<em>float</em>) – the learning rate at the end of each cycle</p></li>
<li><p><strong>cycle_time_epochs</strong> (<em>int</em>) – the number of epochs for the learning rate
scheduler</p></li>
<li><p><strong>epochs</strong> (<em>int</em>) – the number of epochs to train for</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="ignite_simple.trainer.TrainSettings.get_handlers">
<code class="sig-name descname">get_handlers</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; Tuple[Tuple[str, Callable]]<a class="reference internal" href="_modules/ignite_simple/trainer.html#TrainSettings.get_handlers"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite_simple.trainer.TrainSettings.get_handlers" title="Permalink to this definition">¶</a></dt>
<dd><p>This returns handlers except instead of the function descriptions
(module, attribute, args, kwargs), actual callables are provided with
the necessary arguments and keyword arguments already bound.</p>
</dd></dl>

<dl class="method">
<dt id="ignite_simple.trainer.TrainSettings.get_initializer">
<code class="sig-name descname">get_initializer</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; Callable<a class="reference internal" href="_modules/ignite_simple/trainer.html#TrainSettings.get_initializer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite_simple.trainer.TrainSettings.get_initializer" title="Permalink to this definition">¶</a></dt>
<dd><p>This returns the initializer; if it is not specified this is a
no-op. Otherwise, this is the callable which accepts the trainer
and initializes it, with the other arguments and keyword arguments
already bound.</p>
</dd></dl>

<dl class="method">
<dt id="ignite_simple.trainer.TrainSettings.get_loss_loader">
<code class="sig-name descname">get_loss_loader</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; Callable<a class="reference internal" href="_modules/ignite_simple/trainer.html#TrainSettings.get_loss_loader"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite_simple.trainer.TrainSettings.get_loss_loader" title="Permalink to this definition">¶</a></dt>
<dd><p>Gets the actual loss loader callable, which is defined through
loss_loader. This is a callable which returns the <cite>torch.nn.Module</cite>
that goes from the output of the model to a scalar which should be
minimized.</p>
</dd></dl>

<dl class="method">
<dt id="ignite_simple.trainer.TrainSettings.get_model_loader">
<code class="sig-name descname">get_model_loader</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; Callable<a class="reference internal" href="_modules/ignite_simple/trainer.html#TrainSettings.get_model_loader"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite_simple.trainer.TrainSettings.get_model_loader" title="Permalink to this definition">¶</a></dt>
<dd><p>Gets the actual model loader callable, which is defined through
model_loader. This is a callable which returns the <cite>torch.nn.Module</cite>
to train. The resulting callable already has the required arguments
and keyword arguments bound.</p>
</dd></dl>

<dl class="method">
<dt id="ignite_simple.trainer.TrainSettings.get_task_loader">
<code class="sig-name descname">get_task_loader</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; Callable<a class="reference internal" href="_modules/ignite_simple/trainer.html#TrainSettings.get_task_loader"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite_simple.trainer.TrainSettings.get_task_loader" title="Permalink to this definition">¶</a></dt>
<dd><p>Gets the actual task loader callable, which is defined through
task_loader. This is a callable which returns
<cite>(train_set, val_set, train_loader)</cite>, each as defined in TrainState.
The resulting callable already has the required arguments
and keyword arguments bound.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="ignite_simple.trainer.TrainState">
<em class="property">class </em><code class="sig-prename descclassname">ignite_simple.trainer.</code><code class="sig-name descname">TrainState</code><span class="sig-paren">(</span><em class="sig-param">model: torch.nn.modules.module.Module, unstripped_model: Optional[torch.nn.modules.module.Module], train_set: torch.utils.data.dataset.Dataset, val_set: torch.utils.data.dataset.Dataset, train_loader: torch.utils.data.dataloader.DataLoader, optimizer: torch.optim.optimizer.Optimizer, cycle_time_epochs: int, lr_scheduler: ignite.contrib.handlers.param_scheduler.CyclicalScheduler, loss: torch.nn.modules.module.Module, evaluator: ignite.engine.engine.Engine</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ignite_simple/trainer.html#TrainState"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite_simple.trainer.TrainState" title="Permalink to this definition">¶</a></dt>
<dd><p>Describes the state which is passed as the second positional argument to
each event handler, which contains generic information about the training
session that may be useful.</p>
<dl class="field-list simple">
<dt class="field-odd">Variables</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>torch.nn.Module</em>) – the model which is being trained</p></li>
<li><p><strong>unstripped_model</strong> (<em>optional</em><em>[</em><em>torch.nn.Module</em><em>]</em>) – the unstripped model, if
there is one, otherwise just the same reference as model</p></li>
<li><p><strong>train_set</strong> (<em>torch.utils.data.Dataset</em>) – the dataset which is used to
train the model</p></li>
<li><p><strong>val_set</strong> (<em>torch.utils.data.Dataset</em>) – the dataset which is used to
validate the models performance on unseen / held out data.</p></li>
<li><p><strong>train_loader</strong> (<em>torch.utils.data.DataLoader</em>) – the dataloader which is
being used to generate batches from the train set to be passed into the
model. This incorporates the batch size.</p></li>
<li><p><strong>optimizer</strong> (<em>torch.optim.Optimizer</em>) – the optimizer which is used to
update the parameters of the model.</p></li>
<li><p><strong>cycle_time_epochs</strong> (<em>int</em>) – the number of epochs in a complete cycle
of the learning rate, always even.</p></li>
<li><p><strong>lr_scheduler</strong> (<em>ignite.contrib.handlers.param_scheduler.CyclicalScheduler</em>) – the parameter scheduler for the learning rate. Its instance values can
be used to get the learning rate range and length in batches.</p></li>
<li><p><strong>loss</strong> (<em>torch.nn.Module</em>) – the loss function, which accepts
<code class="code docutils literal notranslate"><span class="pre">(input,</span> <span class="pre">target)</span></code> and returns a scalar which is to be minimized.</p></li>
<li><p><strong>evaluator</strong> (<em>ignite.engine.Engine</em>) – the engine which can be used to
gather metrics. Always has a <code class="code docutils literal notranslate"><span class="pre">'loss'</span></code> and <code class="code docutils literal notranslate"><span class="pre">'perf'</span></code> metric, but
may or may not have an <code class="code docutils literal notranslate"><span class="pre">'accuracy'</span></code> metric.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="ignite_simple.trainer.train">
<code class="sig-prename descclassname">ignite_simple.trainer.</code><code class="sig-name descname">train</code><span class="sig-paren">(</span><em class="sig-param">settings: ignite_simple.trainer.TrainSettings</em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="_modules/ignite_simple/trainer.html#train"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite_simple.trainer.train" title="Permalink to this definition">¶</a></dt>
<dd><p>Trains a model with the given settings.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>In order to store anything you will need to use a handler. For example,
a handler for <cite>ignite.engine.Event.COMPLETED</cite> and stores the
model somewhere.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>settings</strong> (<a class="reference internal" href="#ignite_simple.trainer.TrainSettings" title="ignite_simple.trainer.TrainSettings"><em>TrainSettings</em></a>) – The settings to use for training</p>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-ignite_simple.analysis">
<span id="ignite-simple-analysis"></span><h1>ignite_simple.analysis<a class="headerlink" href="#module-ignite_simple.analysis" title="Permalink to this headline">¶</a></h1>
<p>This module is tasked with generating analysis text, images, animations,
and videos using only the output from the model manager, the dataset, the
loss metric, and the accuracy style.</p>
<dl class="function">
<dt id="ignite_simple.analysis.analyze">
<code class="sig-prename descclassname">ignite_simple.analysis.</code><code class="sig-name descname">analyze</code><span class="sig-paren">(</span><em class="sig-param">dataset_loader: Tuple[str, str, tuple, dict], loss_loader: Tuple[str, str, tuple, dict], folder: str, settings: Union[str, ignite_simple.analarams.AnalysisSettings], accuracy_style: str, cores: int</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ignite_simple/analysis.html#analyze"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite_simple.analysis.analyze" title="Permalink to this definition">¶</a></dt>
<dd><p>Performs the requested analysis of the given folder, which is assumed to
have been generated from model_manager.train. The output folder structure
is as follows:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>folder/
    analysis/
        hparams/
            lr/
                i/  (where i=0,1,...)
                    lr_vs_perf.(img)
                    lr_vs_smoothed_perf.(img)
                    lr_vs_perf_deriv.(img)
                    lr_vs_smoothed_perf_deriv.(img)

                lr_vs_perf_*.(img)
                lr_vs_smoothed_perf_*.(img)
                lr_vs_perf_deriv_*.(img)
                lr_vs_smoothed_perf_deriv_*.(img)
                lr_vs_lse_smoothed_perf_then_deriv_*.(img)
            batch/
                i/ (where i=0,1,...)
                    batch_vs_perf.(img)
                    batch_vs_smoothed_perf.(img)
                    batch_vs_perf_deriv.(img)
                    batch_vs_smoothed_perf_deriv.(img)

                batch_vs_perf_*.(img)
                batch_vs_smoothed_perf_*.(img)
                batch_vs_perf_derivs_*.(img)
                batch_vs_smoothed_perf_derivs_*.(img)
                batch_vs_lse_smoothed_perf_then_derivs_*.(img)

            TODO videos &amp; animations
        trials/
            i/  (where i=0,1,...)
                epoch_vs_loss_train.(img) (*)
                epoch_vs_loss_val.(img) (*)
                epoch_vs_perf_train.(img) (*)
                epoch_vs_perf_val.(img) (*)

                pca3dvis_train_draft/
                    Only produced if settings.typical_run_pca3dvis and
                    settings.typical_run_pca3dvis_draft are set, and
                    only done on trial 0
                pca3dvis_train/
                    Only produced if settings.typical_run_pca3dvis and
                    not settings.typical_run_pca3dvis_draft, and only
                    done on trial 0

            epoch_vs_loss_train_*.(img) (*)
            epoch_vs_loss_val_*.(img) (*)
            epoch_vs_smoothed_loss_train_*.(img) (*)
            epoch_vs_smoothed_loss_val_*.(img) (*)
            epoch_vs_perf_train_*.(img) (*)
            epoch_vs_smoothed_perf_train_*.(img) (*)
            epoch_vs_perf_val_*.(img) (*)
            epoch_vs_smoothed_perf_val_*.(img) (*)


            (*)
                Only produced if throughtime.npz is available for
                the trial and settings.training_metric_images is
                set

            TODO more summary of trials
            TODO text &amp; videos &amp; animations

        html/
            See text_analysis.py for details
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dataset_loader</strong> – the module and corresponding attribute that gives a
training and validation dataset when invoked with the specified
arguments and keyword arguments.</p></li>
<li><p><strong>loss_loader</strong> – the module and corresponding attribute that gives a
loss nn.Module when invoked with the specified arguments and keyword
arguments</p></li>
<li><p><strong>folder</strong> – where the model manager saved the trials to analyze</p></li>
<li><p><strong>settings</strong> – the settings for analysis, or the name of the preset to
use. Common preset names are <cite>none</cite>, <cite>text</cite>, <cite>images</cite>, <cite>animations</cite>,
and <cite>videos</cite>. For the full list, see the ignite_simple.analarams
module.</p></li>
<li><p><strong>accuracy_style</strong> – how performance was calculated. one of
‘classification’, ‘multiclass’, and ‘inv-loss’. See train for
details.</p></li>
<li><p><strong>cores</strong> – the number of physical cores this can assume are available
to speed up analysis.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-ignite_simple.text_analysis">
<span id="ignite-simple-text-analysis"></span><h1>ignite_simple.text_analysis<a class="headerlink" href="#module-ignite_simple.text_analysis" title="Permalink to this headline">¶</a></h1>
<p>Produces the html folder for analysis. This is essentially just copying
the html/ folder and preprocessing certain ids.</p>
<dl class="function">
<dt id="ignite_simple.text_analysis.text_analyze">
<code class="sig-prename descclassname">ignite_simple.text_analysis.</code><code class="sig-name descname">text_analyze</code><span class="sig-paren">(</span><em class="sig-param">settings: ignite_simple.analarams.AnalysisSettings</em>, <em class="sig-param">folder: str</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ignite_simple/text_analysis.html#text_analyze"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite_simple.text_analysis.text_analyze" title="Permalink to this definition">¶</a></dt>
<dd><p>Analyzes the given folder produced by the model manager, storing the
results in folder/analysis/html</p>
<dl class="simple">
<dt>Args:</dt><dd><p>settings (AnalysisSettings): the analysis settings.
folder (str): the folder that was passed to the model manager.</p>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-ignite_simple.range_finder">
<span id="ignite-simple-range-finder"></span><h1>ignite_simple.range_finder<a class="headerlink" href="#module-ignite_simple.range_finder" title="Permalink to this headline">¶</a></h1>
<p>This module is responsible for finding a good range of values within which
a measure is increasing most rapidly. This works best when the y-values have
already been smoothed.</p>
<dl class="function">
<dt id="ignite_simple.range_finder.autosmooth">
<code class="sig-prename descclassname">ignite_simple.range_finder.</code><code class="sig-name descname">autosmooth</code><span class="sig-paren">(</span><em class="sig-param">arr: numpy.ndarray</em>, <em class="sig-param">axis: int = -1</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ignite_simple/range_finder.html#autosmooth"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite_simple.range_finder.autosmooth" title="Permalink to this definition">¶</a></dt>
<dd><p>Causes scipy.signal.savgol_filter on the given data for the given
dimension with the default settings.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>arr</strong> – the array to smooth</p></li>
<li><p><strong>dim</strong> – the smooth dimension</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="ignite_simple.range_finder.find_with_derivs">
<code class="sig-prename descclassname">ignite_simple.range_finder.</code><code class="sig-name descname">find_with_derivs</code><span class="sig-paren">(</span><em class="sig-param">xs: numpy.ndarray</em>, <em class="sig-param">derivs: numpy.ndarray</em><span class="sig-paren">)</span> &#x2192; Tuple[float, float]<a class="reference internal" href="_modules/ignite_simple/range_finder.html#find_with_derivs"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite_simple.range_finder.find_with_derivs" title="Permalink to this definition">¶</a></dt>
<dd><p>Finds the range in derivs wherein the derivative is always
positive. From these intervals, this returns specifically the one with
the greatest integral.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs</strong> (<em>np.ndarray</em>) – with shape <cite>(points,)</cite>, the x-values corresponding to
the derivatives</p></li>
<li><p><strong>derivs</strong> (<em>np.ndarray</em>) – with shape <cite>(points,)</cite>, the relevant derivatives</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>the <cite>(min, max)</cite> for the best interval in xs that has positive
derivative in ys. Where multiple such intervals exist, this is the
one with the greatest integral</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="ignite_simple.range_finder.nonzero_intervals">
<code class="sig-prename descclassname">ignite_simple.range_finder.</code><code class="sig-name descname">nonzero_intervals</code><span class="sig-paren">(</span><em class="sig-param">vec: numpy.ndarray</em><span class="sig-paren">)</span> &#x2192; numpy.ndarray<a class="reference internal" href="_modules/ignite_simple/range_finder.html#nonzero_intervals"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite_simple.range_finder.nonzero_intervals" title="Permalink to this definition">¶</a></dt>
<dd><p>Find which intervals in the given vector are non-zero.</p>
<p>Adapted from <a class="reference external" href="https://stackoverflow.com/a/27642744">https://stackoverflow.com/a/27642744</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>vec</strong> (<em>np.ndarray</em>) – the vector to scan for non-zero intervals</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a list [x1, x2, …, xn] such that [xi, xi+1) is a nonzero
interval in vec</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="ignite_simple.range_finder.smooth_window_size">
<code class="sig-prename descclassname">ignite_simple.range_finder.</code><code class="sig-name descname">smooth_window_size</code><span class="sig-paren">(</span><em class="sig-param">npts: int</em><span class="sig-paren">)</span> &#x2192; int<a class="reference internal" href="_modules/ignite_simple/range_finder.html#smooth_window_size"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite_simple.range_finder.smooth_window_size" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the a heuristic for the window size for smoothing an array with
the given number of points. Specifically, this is 1/10 the number of points
or 101, whichever is smaller.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>npts</strong> (<em>int</em>) – the number of data points you have</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>suggested window size for smoothing the data</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="ignite_simple.range_finder.trim_range_derivs">
<code class="sig-prename descclassname">ignite_simple.range_finder.</code><code class="sig-name descname">trim_range_derivs</code><span class="sig-paren">(</span><em class="sig-param">xs: numpy.ndarray</em>, <em class="sig-param">derivs: numpy.ndarray</em>, <em class="sig-param">x_st_ind: int</em>, <em class="sig-param">x_en_ind: int</em><span class="sig-paren">)</span> &#x2192; Tuple[int, int]<a class="reference internal" href="_modules/ignite_simple/range_finder.html#trim_range_derivs"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite_simple.range_finder.trim_range_derivs" title="Permalink to this definition">¶</a></dt>
<dd><p>Given that we have found a good interval in the xs for which the derivs
is positive, it may be possible that the bulk of the integral can be
maintained while reducing the width of the integral. This function returns
a new interval which is a subset of the given interval for which the
bulk of the integral is maintained.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs</strong> (<em>np.ndarray</em>) – with shape <cite>(points,)</cite>, the x-values corresponding
to the derivatives</p></li>
<li><p><strong>derivs</strong> (<em>np.ndarray</em>) – with shape <cite>(points,)</cite>, the relevant derivatives</p></li>
<li><p><strong>x_st_ind</strong> (<em>int</em>) – the index in xs the good interval starts at</p></li>
<li><p><strong>x_en_ind</strong> (<em>int</em>) – the index in xs the good interval ends at</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><cite>(x_st_ind, x_end_ind)</cite> which is a subset of the passed interval</p>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-ignite_simple.tuner">
<span id="ignite-simple-tuner"></span><h1>ignite_simple.tuner<a class="headerlink" href="#module-ignite_simple.tuner" title="Permalink to this headline">¶</a></h1>
<p>This module is responsible for tuning the learning rate and batch size for
training a module.</p>
<dl class="function">
<dt id="ignite_simple.tuner.tune">
<code class="sig-prename descclassname">ignite_simple.tuner.</code><code class="sig-name descname">tune</code><span class="sig-paren">(</span><em class="sig-param">model_loader: Tuple[str, str, tuple, dict], dataset_loader: Tuple[str, str, tuple, dict], loss_loader: Tuple[str, str, tuple, dict], accuracy_style: str, folder: str, cores: int, settings: ignite_simple.hyperparams.HyperparameterSettings, store_up_to: ignite_simple.analarams.AnalysisSettings, logger: logging.Logger = None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ignite_simple/tuner.html#tune"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite_simple.tuner.tune" title="Permalink to this definition">¶</a></dt>
<dd><p>Finds the optimal learning rate and batch size for the specified model
on the specified dataset trained with the given loss. Stores the following
information:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>folder/
    final.json
        {&#39;lr_start&#39;: float, &#39;lr_end&#39;: float, &#39;batch_size&#39;: float,
         &#39;cycle_size_epochs&#39;: int, &#39;epochs&#39;: int}
    misc.json
        Variables that went into the final output. Typically selected
        via heuristics, constants, or come from the hyperparameter
        settings. Some may be deduced from the numpy array files
        directly

        {
            &#39;initial_batch_size&#39;: int,
            &#39;initial_cycle_time&#39;: int,
            &#39;initial_min_lr&#39;: float,
            &#39;initial_max_lr&#39;: float,
            &#39;initial_lr_num_to_val&#39;: int,
            &#39;initial_lr_num_trials&#39;: int,
            &#39;initial_lr_window_size&#39;: int,
            &#39;initial_lr_sweep_result_min&#39;: float,
            &#39;initial_lr_sweep_result_max&#39;: float,
            &#39;second_min_lr&#39;: float,
            &#39;second_max_lr&#39;: float
        }

    lr_vs_perf.npz
        lrs=np.ndarray[number of batches]
        perfs=np.ndarray[trials, number of batches]
        smoothed_perfs=np.ndarray[trials, number of batches]
        lse_smoothed_perfs=np.ndarray[trials, number of batches]
        perf_derivs=np.ndarray[trials, number_of_batches]
        smoothed_perf_derivs=np.ndarray[trials, number of batches]
        mean_smoothed_perf_derivs=np.ndarray[number of batches]
        lse_smoothed_perf_then_derivs=np.ndarray[number of batches]
            lse = log sum exp. when there are many trials, the mean
            gets overly pessimistic from bad initializations,
            so LSE is more stable. however, we can&#39;t do lse on the
            smoothed derivatives because then derivatives will tend
            to be positive everywhere, so we have to smooth first,
            then take lse, then take derivative
        lr_range=np.ndarray[2]
            min, max for the good range of learning rates
    bs_vs_perf.npz  (bs=batch_size)
        Where a single batch is tried multiple times, we take the
        mean over those times to ensure bss contains only unique
        values and hence can be treated like lrs

        bss=np.ndarray[number of batches]
        perfs=np.ndarray[trials, number of batches]
        smoothed_perfs=np.ndarray[number of batches]
        lse_smoothed_perfs=np.ndarray[number of batches]
        perf_derivs=np.ndarray[trials, number_of_batches]
        smoothed_perf_derivs=np.ndarray[trials, number of batches]
        mean_smoothed_perf_derivs=np.ndarray[number of batches]
        lse_smoothed_perf_then_derivs=np.ndarray[number of batches]
        bs_range=np.ndarray[2]
            min, max for the good range of batch sizes
    lr_vs_perf2.npz
        only stored if settings.rescan_lr_after_bs. looks exactly
        like lr_vs_perf.npz, except these runs are performed with
        the newly selected batch size
    bs_sampled.npz
        only stored if settings.batch_pts &gt; 0

        bss=np.ndarray[num bs attempted]
        final=np.ndarray[num bs attempted, trials]
            final performance for batch size i for each trial
        lse_final=np.ndarray[num bs attempted]
            final logsumexp performance for each batch size, argmax
            is the selected batch size. If you want this to nicely
            be below the maximum, subtract log(trials) and note
            this does not effect the argmax

        raw_i=np.ndarray[trials, number of batches]
            only if store_up_to.hparam_selection_specific_imgs,
            same for the *_raw_i

            i is a sampled batch size and raw_i[t, j] is the
            performance of the model after iteration j for
            batch size i on trial t.
        smoothed_raw_i=np.ndarray[trials, number of batches]
        lse_smoothed_raw_i=np.ndarray[number of batches]
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_loader</strong> – <p>describes which module and corresponding attribute can
be passed what arguments and keyword arguments to produce the
nn.Module with a random initialization which can be trained</p>
</p></li>
<li><p><strong>dataset_loader</strong> – describes which module and corresponding attribute
can be passed what arguments and keyword arguments to produce the
training dataset and validation dataset.</p></li>
<li><p><strong>loss_loader</strong> – describes which module and corresponding attribute can
be passed what arguments and keyword arguments to produce the nn.Module
that converts (y_pred, y) to a scalar which should be minimized</p></li>
<li><p><strong>folder</strong> – where to save the output to</p></li>
<li><p><strong>cores</strong> – how many cores to use; 1 for just the main process</p></li>
<li><p><strong>settings</strong> – the settings to use to tune the learning rate and batch
size</p></li>
<li><p><strong>store_up_to</strong> – the information stored should be at least what is
required to produce this analysis</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-ignite_simple.helper">
<span id="ignite-simple-helper"></span><h1>ignite_simple.helper<a class="headerlink" href="#module-ignite_simple.helper" title="Permalink to this headline">¶</a></h1>
<p>This acts as a potential runner for files, or as an import to reduce the
amount of boilerplate in a runner. Given a module which has a model() function,
dataset() function, and loss() function this uses argparse to fill in the rest
of the parameters to train() or reanalyze() as requested.</p>
<dl class="field-list simple">
<dt class="field-odd">Example</dt>
<dd class="field-odd"><p></p></dd>
</dl>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># in file mymod.py</span>
<span class="kn">import</span> <span class="nn">ignite_simple.helper</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="k">def</span> <span class="nf">model</span><span class="p">():</span>
    <span class="k">pass</span> <span class="c1"># omitted, should return torch.nn.Module</span>

<span class="k">def</span> <span class="nf">dataset</span><span class="p">():</span>
    <span class="k">pass</span> <span class="c1"># omitted, return train_set, val_set</span>

<span class="n">accuracy_style</span> <span class="o">=</span> <span class="s1">&#39;multiclass&#39;</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span> <span class="c1"># any callable that returns a loss works</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="n">ignite_simple</span><span class="o">.</span><span class="n">helper</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>&gt; python3 -m mymod --help
</pre></div>
</div>
<dl class="function">
<dt id="ignite_simple.helper.handle">
<code class="sig-prename descclassname">ignite_simple.helper.</code><code class="sig-name descname">handle</code><span class="sig-paren">(</span><em class="sig-param">module=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ignite_simple/helper.html#handle"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite_simple.helper.handle" title="Permalink to this definition">¶</a></dt>
<dd><p>Uses the given module containing model(), dataset(), loss() and
accuracy_style as the module for train() or analyze() with everything
else determined by the command line arguments.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>module</strong> – module containing model(), dataset(), loss(), accuracy_style</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="ignite_simple.helper.reanalyze">
<code class="sig-prename descclassname">ignite_simple.helper.</code><code class="sig-name descname">reanalyze</code><span class="sig-paren">(</span><em class="sig-param">module</em>, <em class="sig-param">args</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ignite_simple/helper.html#reanalyze"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite_simple.helper.reanalyze" title="Permalink to this definition">¶</a></dt>
<dd><p>Uses the given arguments from argparse to determine the arguments to
ignite_simple.reanalyze</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>module</strong> – module containing model(), dataset(), loss(), accuracy_style</p></li>
<li><p><strong>args</strong> – argparse result</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="ignite_simple.helper.train">
<code class="sig-prename descclassname">ignite_simple.helper.</code><code class="sig-name descname">train</code><span class="sig-paren">(</span><em class="sig-param">module</em>, <em class="sig-param">args</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ignite_simple/helper.html#train"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite_simple.helper.train" title="Permalink to this definition">¶</a></dt>
<dd><p>Uses the given arguments from argparse to determine the arguments to
ignite_simple.train</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>module</strong> – module containing the model(), dataset(), loss(), and
accuracy_style</p></li>
<li><p><strong>args</strong> – argparse result</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-ignite_simple.utils">
<span id="ignite-simple-utils"></span><h1>ignite_simple.utils<a class="headerlink" href="#module-ignite_simple.utils" title="Permalink to this headline">¶</a></h1>
<p>Utility functions which are used through ignite-simple but are short
enough not to warrant their own module.</p>
<dl class="function">
<dt id="ignite_simple.utils.create_partial_loader">
<code class="sig-prename descclassname">ignite_simple.utils.</code><code class="sig-name descname">create_partial_loader</code><span class="sig-paren">(</span><em class="sig-param">dset: torch.utils.data.dataset.Dataset</em>, <em class="sig-param">amt: int</em>, <em class="sig-param">batch_size: int = 256</em><span class="sig-paren">)</span> &#x2192; torch.utils.data.dataloader.DataLoader<a class="reference internal" href="_modules/ignite_simple/utils.html#create_partial_loader"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite_simple.utils.create_partial_loader" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates a dataloader which loads only a random subset of the
specified length from the dataset, using the specified batch size.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dset</strong> – the dataset to create a loader for a partial subset of</p></li>
<li><p><strong>amt</strong> – the number of items in the partial subset</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>the described dataloader with a reasonable batch size</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="ignite_simple.utils.fix_imports">
<code class="sig-prename descclassname">ignite_simple.utils.</code><code class="sig-name descname">fix_imports</code><span class="sig-paren">(</span><em class="sig-param">loader: Tuple[str, str, tuple, dict]</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ignite_simple/utils.html#fix_imports"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite_simple.utils.fix_imports" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the loader which represents the same callable as the given one,
except potentially with the __main__ name replaced with the correct module
name.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>loader</strong> – the loader whose imports might need to be cleaned</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>the cleaned loader</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="ignite_simple.utils.invoke">
<code class="sig-prename descclassname">ignite_simple.utils.</code><code class="sig-name descname">invoke</code><span class="sig-paren">(</span><em class="sig-param">loader: Tuple[str, str, tuple, dict]</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ignite_simple/utils.html#invoke"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite_simple.utils.invoke" title="Permalink to this definition">¶</a></dt>
<dd><p>Invokes the callable which has the given name in the given module,
using the given arguments and keyword arguments</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>loader</strong> – (module, attrname, args, kwargs) - the callable to invoke</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>the result of the callable</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="ignite_simple.utils.noop">
<code class="sig-prename descclassname">ignite_simple.utils.</code><code class="sig-name descname">noop</code><span class="sig-paren">(</span><em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ignite_simple/utils.html#noop"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite_simple.utils.noop" title="Permalink to this definition">¶</a></dt>
<dd><p>This function does nothing.</p>
</dd></dl>

<dl class="function">
<dt id="ignite_simple.utils.split">
<code class="sig-prename descclassname">ignite_simple.utils.</code><code class="sig-name descname">split</code><span class="sig-paren">(</span><em class="sig-param">full: torch.utils.data.dataset.Dataset</em>, <em class="sig-param">val_perc: float</em>, <em class="sig-param">filen: str = None</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.utils.data.dataset.Dataset, torch.utils.data.dataset.Dataset]<a class="reference internal" href="_modules/ignite_simple/utils.html#split"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite_simple.utils.split" title="Permalink to this definition">¶</a></dt>
<dd><p>Splits the given dataset into two datasets, the first of which has
(1 - val_perc) fraction of the data and the other has val_perc fraction
of the data, distributed randomly.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>full</strong> (<em>data.Dataset</em>) – the entire dataset to split into two</p></li>
<li><p><strong>val_perc</strong> (<em>float</em>) – the amount to be broken away from full</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>(train_set, val_set)</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="ignite_simple.utils.task_loader">
<code class="sig-prename descclassname">ignite_simple.utils.</code><code class="sig-name descname">task_loader</code><span class="sig-paren">(</span><em class="sig-param">dataset_loader</em>, <em class="sig-param">batch_size</em>, <em class="sig-param">shuffle</em>, <em class="sig-param">drop_last</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ignite_simple/utils.html#task_loader"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite_simple.utils.task_loader" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates a task loader from a dataset loader.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dataset_loader</strong> – the dataset loader (str, str, tuple, dict)</p></li>
<li><p><strong>batch_size</strong> – the batch size for the data loader</p></li>
<li><p><strong>shuffle</strong> – if the training dataset should be shuffled between epochs</p></li>
<li><p><strong>drop_last</strong> – if the last batch should be dropped if its not the
same size as the rest. should only be used if shuffle is True</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-ignite_simple.figure_utils">
<span id="ignite-simple-figure-utils"></span><h1>ignite_simple.figure_utils<a class="headerlink" href="#module-ignite_simple.figure_utils" title="Permalink to this headline">¶</a></h1>
<p>Some utility functions related to creating good looking figures.</p>
<dl class="function">
<dt id="ignite_simple.figure_utils.fig_exists">
<code class="sig-prename descclassname">ignite_simple.figure_utils.</code><code class="sig-name descname">fig_exists</code><span class="sig-paren">(</span><em class="sig-param">outfile_wo_ext: str</em><span class="sig-paren">)</span> &#x2192; bool<a class="reference internal" href="_modules/ignite_simple/figure_utils.html#fig_exists"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite_simple.figure_utils.fig_exists" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns true if the files from save_fig with the given outfile already
exist.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>outfile_wo_ext</strong> (<em>str</em>) – where we expect the file to have been saved</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>True if the file(s) exists, False otherwise</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="ignite_simple.figure_utils.make_vs_title">
<code class="sig-prename descclassname">ignite_simple.figure_utils.</code><code class="sig-name descname">make_vs_title</code><span class="sig-paren">(</span><em class="sig-param">x: str</em>, <em class="sig-param">y: str</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ignite_simple/figure_utils.html#make_vs_title"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite_simple.figure_utils.make_vs_title" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates the axes title for a plot with the given x-axis variable and
y-axis variable</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>str</em>) – the name for the x-variable</p></li>
<li><p><strong>y</strong> (<em>str</em>) – the name for the y-variable</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The correct axes title</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="ignite_simple.figure_utils.save_fig">
<code class="sig-prename descclassname">ignite_simple.figure_utils.</code><code class="sig-name descname">save_fig</code><span class="sig-paren">(</span><em class="sig-param">fig: matplotlib.figure.Figure</em>, <em class="sig-param">ax: matplotlib.axes._axes.Axes</em>, <em class="sig-param">title: str</em>, <em class="sig-param">outfile_wo_ext: str</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ignite_simple/figure_utils.html#save_fig"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite_simple.figure_utils.save_fig" title="Permalink to this definition">¶</a></dt>
<dd><p>Saves the given figure with many different commonly used figure sizes,
resizing labels and titles as appropriate. This technique works only for
a single axis plot, since for other styles different font sizes would be
appropriate.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>fig</strong> (<em>Figure</em>) – The figure to save</p></li>
<li><p><strong>ax</strong> (<em>Axes</em>) – The axis on the figure</p></li>
<li><p><strong>title</strong> (<em>str</em>) – The title of the plot</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="ignite_simple.figure_utils.set_ticklabel_sizes">
<code class="sig-prename descclassname">ignite_simple.figure_utils.</code><code class="sig-name descname">set_ticklabel_sizes</code><span class="sig-paren">(</span><em class="sig-param">fig: matplotlib.figure.Figure</em>, <em class="sig-param">ax: matplotlib.axes._axes.Axes</em>, <em class="sig-param">digital: bool</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ignite_simple/figure_utils.html#set_ticklabel_sizes"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite_simple.figure_utils.set_ticklabel_sizes" title="Permalink to this definition">¶</a></dt>
<dd><p>Updates the sizes of the tick labels for the given figure based on its
canvas size and canvas dpi.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>fig</strong> (<em>Figure</em>) – The figure to update</p></li>
<li><p><strong>ax</strong> (<em>Axes</em>) – The specific axes within the figure to update</p></li>
<li><p><strong>digital</strong> (<em>bool</em>) – True if this is for digital display,
False for physical display</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="ignite_simple.figure_utils.set_title">
<code class="sig-prename descclassname">ignite_simple.figure_utils.</code><code class="sig-name descname">set_title</code><span class="sig-paren">(</span><em class="sig-param">fig: matplotlib.figure.Figure</em>, <em class="sig-param">ax: matplotlib.axes._axes.Axes</em>, <em class="sig-param">title: str</em>, <em class="sig-param">digital: bool</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ignite_simple/figure_utils.html#set_title"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite_simple.figure_utils.set_title" title="Permalink to this definition">¶</a></dt>
<dd><p>Sets the title for the given axes to the given value. This is more
particular than the default matplotlib Axes.set_title.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>fig</strong> (<em>Figure</em>) – the figure the axes is in</p></li>
<li><p><strong>ax</strong> (<em>Axes</em>) – the axes which you want to have a title</p></li>
<li><p><strong>title</strong> (<em>str</em>) – the desired title text</p></li>
<li><p><strong>digital</strong> (<em>bool</em>) – if True, a large font size is selected. Otherwise,
a smaller font size is selected</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>TextCollection that was added</p>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-ignite_simple.vary_bs_loader">
<span id="ignite-simple-vary-bs-loader"></span><h1>ignite_simple.vary_bs_loader<a class="headerlink" href="#module-ignite_simple.vary_bs_loader" title="Permalink to this headline">¶</a></h1>
<p>A torch dataloader which varies the batch size between two amounts
over the course of a specified number of epochs of an underlying dataset. The
variation spends more time at lower batch sizes than at higher batch sizes, for
convenience of implementation and to account for the higher stochasticity at
lower batch sizes</p>
<dl class="class">
<dt id="ignite_simple.vary_bs_loader.BatchSizeVaryingDataLoader">
<em class="property">class </em><code class="sig-prename descclassname">ignite_simple.vary_bs_loader.</code><code class="sig-name descname">BatchSizeVaryingDataLoader</code><span class="sig-paren">(</span><em class="sig-param">dataset</em>, <em class="sig-param">start_batch_size</em>, <em class="sig-param">end_batch_size</em>, <em class="sig-param">epochs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ignite_simple/vary_bs_loader.html#BatchSizeVaryingDataLoader"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite_simple.vary_bs_loader.BatchSizeVaryingDataLoader" title="Permalink to this definition">¶</a></dt>
<dd><p>A dataloader which acts on an underlying dataset, varying the batch size
linearly between two specified amounts over a given period of time. Note
that this redefines one epoch to be the specified amount of time!</p>
<dl class="field-list simple">
<dt class="field-odd">Variables</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dataset</strong> (<em>data.Dataset</em>) – the underlying dataset from which points and
labels are being pulled</p></li>
<li><p><strong>start_batch_size</strong> (<em>int</em>) – the starting batch size</p></li>
<li><p><strong>end_batch_size</strong> (<em>int</em>) – the final batch size</p></li>
<li><p><strong>epochs</strong> (<em>int</em>) – the number of epochs over which the underlying dataset
is iterated over</p></li>
<li><p><strong>last_iter</strong> (<em>iterator</em>) – the last real iterator that was created</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="ignite_simple.vary_bs_loader.BatchSizeVaryingDataLoader.dry_iter">
<code class="sig-name descname">dry_iter</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/ignite_simple/vary_bs_loader.html#BatchSizeVaryingDataLoader.dry_iter"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite_simple.vary_bs_loader.BatchSizeVaryingDataLoader.dry_iter" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates a ‘dry’ iterator which does not actually produce anything
but has the correct length and updates last_batch_size normally</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-ignite_simple.dispatcher">
<span id="ignite-simple-dispatcher"></span><h1>ignite_simple.dispatcher<a class="headerlink" href="#module-ignite_simple.dispatcher" title="Permalink to this headline">¶</a></h1>
<p>This package handles accepting a list of jobs and then deciding which of
them to run in what order.</p>
<p>This module is intended for use by the analysis module for managing all the
jobs it has to do. The analysis package tends to have many jobs are all fairly
independent of each other. Things like rq and celery are way over-engineered
for this task.</p>
<dl class="class">
<dt id="ignite_simple.dispatcher.MainToWorkerConnection">
<em class="property">class </em><code class="sig-prename descclassname">ignite_simple.dispatcher.</code><code class="sig-name descname">MainToWorkerConnection</code><span class="sig-paren">(</span><em class="sig-param">proc: multiprocessing.context.Process</em>, <em class="sig-param">jobq: pympanim.zeromqqueue.ZeroMQQueue</em>, <em class="sig-param">ackq: pympanim.zeromqqueue.ZeroMQQueue</em>, <em class="sig-param">sleep_delay: float</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ignite_simple/dispatcher.html#MainToWorkerConnection"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite_simple.dispatcher.MainToWorkerConnection" title="Permalink to this definition">¶</a></dt>
<dd><p>Describes a connection from the main process to the worker process</p>
<dl class="field-list simple">
<dt class="field-odd">Variables</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>process</strong> (<em>Process</em>) – the actual worker process</p></li>
<li><p><strong>jobq</strong> (<em>ZeroMQQueue</em>) – the queue that jobs can be sent through to this
worker</p></li>
<li><p><strong>ackq</strong> (<em>ZeroMQQueue</em>) – the queue that the worker sends job completed
notifications through</p></li>
<li><p><strong>cores</strong> (<em>optional</em><em>[</em><em>int</em><em>]</em>) – the number of cores that this worker is
currently using, or None if the worker is not doing anything right
now</p></li>
<li><p><strong>sleep_delay</strong> (<em>float</em>) – the current sleep delay for this worker</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="ignite_simple.dispatcher.MainToWorkerConnection.close">
<code class="sig-name descname">close</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/ignite_simple/dispatcher.html#MainToWorkerConnection.close"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite_simple.dispatcher.MainToWorkerConnection.close" title="Permalink to this definition">¶</a></dt>
<dd><p>Shuts down the worker</p>
</dd></dl>

<dl class="method">
<dt id="ignite_simple.dispatcher.MainToWorkerConnection.is_ready">
<code class="sig-name descname">is_ready</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; bool<a class="reference internal" href="_modules/ignite_simple/dispatcher.html#MainToWorkerConnection.is_ready"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite_simple.dispatcher.MainToWorkerConnection.is_ready" title="Permalink to this definition">¶</a></dt>
<dd><p>Checks to see if the worker is ready to get a new task.</p>
</dd></dl>

<dl class="method">
<dt id="ignite_simple.dispatcher.MainToWorkerConnection.send">
<code class="sig-name descname">send</code><span class="sig-paren">(</span><em class="sig-param">task: ignite_simple.dispatcher.Task</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ignite_simple/dispatcher.html#MainToWorkerConnection.send"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite_simple.dispatcher.MainToWorkerConnection.send" title="Permalink to this definition">¶</a></dt>
<dd><p>Tells the worker to perform the given task.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>task</strong> – the task to perform</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="ignite_simple.dispatcher.MainToWorkerConnection.update_sleep_delay">
<code class="sig-name descname">update_sleep_delay</code><span class="sig-paren">(</span><em class="sig-param">delay: float</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ignite_simple/dispatcher.html#MainToWorkerConnection.update_sleep_delay"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite_simple.dispatcher.MainToWorkerConnection.update_sleep_delay" title="Permalink to this definition">¶</a></dt>
<dd><p>Tells the worker to poll for jobs with the given inter-poll delay</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="ignite_simple.dispatcher.Task">
<em class="property">class </em><code class="sig-prename descclassname">ignite_simple.dispatcher.</code><code class="sig-name descname">Task</code><span class="sig-paren">(</span><em class="sig-param">module: str, attrname: str, args: tuple, kwargs: dict, cores: Optional[int]</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ignite_simple/dispatcher.html#Task"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite_simple.dispatcher.Task" title="Permalink to this definition">¶</a></dt>
<dd><p>A description of a task.</p>
<dl class="field-list simple">
<dt class="field-odd">Variables</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>module</strong> (<em>str</em>) – the name of the module which contains the callable</p></li>
<li><p><strong>attrname</strong> (<em>str</em>) – the name of the attribute within the module</p></li>
<li><p><strong>args</strong> (<em>tuple</em>) – the arguments to pass to the callable</p></li>
<li><p><strong>kwargs</strong> (<em>dict</em>) – the keyword arguments to pass to the callable</p></li>
<li><p><strong>cores</strong> (<em>optional</em><em>[</em><em>int</em><em>]</em>) – the number of cores this task will use, None
for all cores</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="ignite_simple.dispatcher.dispatch">
<code class="sig-prename descclassname">ignite_simple.dispatcher.</code><code class="sig-name descname">dispatch</code><span class="sig-paren">(</span><em class="sig-param">tasks: Tuple[ignite_simple.dispatcher.Task], total_cores: int, suggested_imports: Tuple[str] = ()</em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="_modules/ignite_simple/dispatcher.html#dispatch"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite_simple.dispatcher.dispatch" title="Permalink to this definition">¶</a></dt>
<dd><p>Dispatches the given tasks using greedy selection such that no more
than the specified number of cores are in use at once, where possible
to do so. This uses a greedy selection of tasks.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tasks</strong> – an iterable of tasks to dispatch</p></li>
<li><p><strong>total_cores</strong> – the target number of cores to use at once</p></li>
<li><p><strong>suggested_imports</strong> – things which are imported in each worker process
during the spawning phase, which causes jobs to be processed more
smoothly.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="indices-and-tables">
<h1>Indices and tables<a class="headerlink" href="#indices-and-tables" title="Permalink to this headline">¶</a></h1>
<ul class="simple">
<li><p><a class="reference internal" href="genindex.html"><span class="std std-ref">Index</span></a></p></li>
<li><p><a class="reference internal" href="py-modindex.html"><span class="std std-ref">Module Index</span></a></p></li>
<li><p><a class="reference internal" href="search.html"><span class="std std-ref">Search Page</span></a></p></li>
</ul>
</div>


           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>