

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Ignite Simple &mdash; ignite-simple 0.0.1 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script type="text/javascript" src="_static/jquery.js"></script>
        <script type="text/javascript" src="_static/underscore.js"></script>
        <script type="text/javascript" src="_static/doctools.js"></script>
        <script type="text/javascript" src="_static/language_data.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="#" class="icon icon-home"> ignite-simple
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <!-- Local TOC -->
              <div class="local-toc"><ul>
<li><a class="reference internal" href="#">Ignite Simple</a></li>
<li><a class="reference internal" href="#module-ignite_simple.analarams">ignite_simple.analarams</a></li>
<li><a class="reference internal" href="#module-ignite_simple.hyperparams">ignite_simple.hyperparams</a></li>
<li><a class="reference internal" href="#module-ignite_simple.trainer">ignite_simple.trainer</a></li>
<li><a class="reference internal" href="#module-ignite_simple.range_finder">ignite_simple.range_finder</a></li>
<li><a class="reference internal" href="#module-ignite_simple.tuner">ignite_simple.tuner</a></li>
<li><a class="reference internal" href="#module-ignite_simple.utils">ignite_simple.utils</a></li>
<li><a class="reference internal" href="#module-ignite_simple.vary_bs_loader">ignite_simple.vary_bs_loader</a></li>
<li><a class="reference internal" href="#indices-and-tables">Indices and tables</a></li>
</ul>
</div>
            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="#">ignite-simple</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="#">Docs</a> &raquo;</li>
        
      <li>Ignite Simple</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/index.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="ignite-simple">
<h1>Ignite Simple<a class="headerlink" href="#ignite-simple" title="Permalink to this headline">¶</a></h1>
<div class="toctree-wrapper compound">
</div>
</div>
<div class="section" id="module-ignite_simple.analarams">
<span id="ignite-simple-analarams"></span><h1>ignite_simple.analarams<a class="headerlink" href="#module-ignite_simple.analarams" title="Permalink to this headline">¶</a></h1>
<p>Describes parameters relevant for analysis. The parameters are specified
for the output, and what’s required to produce that output is calculated from
that.</p>
<dl class="class">
<dt id="ignite_simple.analarams.AnalysisSettings">
<em class="property">class </em><code class="sig-prename descclassname">ignite_simple.analarams.</code><code class="sig-name descname">AnalysisSettings</code><span class="sig-paren">(</span><em class="sig-param">lr_selection_explanation: bool</em>, <em class="sig-param">lr_selection_results: bool</em>, <em class="sig-param">batch_selection_explanation: bool</em>, <em class="sig-param">batch_selection_results: bool</em>, <em class="sig-param">hparam_selection_specifics: bool</em>, <em class="sig-param">hparam_selection_specific_imgs: bool</em>, <em class="sig-param">training_explanation: bool</em>, <em class="sig-param">training_metrics: bool</em>, <em class="sig-param">training_metric_imgs: bool</em>, <em class="sig-param">final_metrics: bool</em>, <em class="sig-param">typical_run_pca3dvis: bool</em>, <em class="sig-param">typical_run_pca3dvis_draft: bool</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ignite_simple/analarams.html#AnalysisSettings"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite_simple.analarams.AnalysisSettings" title="Permalink to this definition">¶</a></dt>
<dd><p>Describes the analysis settings. Note that, where relevant and
equivalent, parallel computations are described as if they were
performed sequentially.</p>
<dl class="field-list simple">
<dt class="field-odd">Variables</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lr_selection_explanation</strong> (<em>bool</em>) – True if the output should include a
broad text explanation of how the learning rate was selected, False
otherwise.</p></li>
<li><p><strong>lr_selection_results</strong> (<em>bool</em>) – True if the output should include a text
explanation of the selected learning rate, False otherwise.</p></li>
<li><p><strong>batch_selection_explanation</strong> (<em>bool</em>) – True if the output should include
a broad text explanation of how the minibatch size was selected, False
otherwise.</p></li>
<li><p><strong>batch_selection_results</strong> (<em>bool</em>) – True if the output should include a
text explanation of the selected minibatch size, False otherwise.</p></li>
<li><p><strong>hparam_selection_specifics</strong> (<em>bool</em>) – True if the output should include
a text explanation about how specifically we came about selecting the
learning rate and batch size, by going through the numbers, False
otherwise.</p></li>
<li><p><strong>hparam_selection_specific_imgs</strong> (<em>bool</em>) – True if the output should
include figures with captions for the hyper paramater selection process
as it occurred for this model specifically, False otherwise.</p></li>
<li><p><strong>training_explanation</strong> (<em>bool</em>) – True if the output should include a broad
text explanation of the training procedure, False otherwise.</p></li>
<li><p><strong>training_metrics</strong> (<em>bool</em>) – True if the output should include text metrics
for the models performance through training, False otherwise.</p></li>
<li><p><strong>training_metric_imgs</strong> (<em>bool</em>) – True if the output should include figures
with captions for the performance of the model through training, i.e.,
accuracy vs epoch and loss vs epoch figures.</p></li>
<li><p><strong>final_metrics</strong> (<em>bool</em>) – True if the output should include in text the
final accuracy and loss, False otherwise.</p></li>
<li><p><strong>typical_run_pca3dvis</strong> (<em>bool</em>) – True if the output should include a video
from pca3dvis for the points as they moved through the network, False
otherwise.</p></li>
<li><p><strong>typical_run_pca3dvis_draft</strong> (<em>bool</em>) – If <cite>typical_run_pca3dvis</cite> is True,
then the value of <cite>typical_run_pca3dvis_draft</cite> corresponds to if the
video should have draft settings. If <cite>typical_run_pca3dvis</cite> is False,
this has no effect.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="ignite_simple.analarams.animations">
<code class="sig-prename descclassname">ignite_simple.analarams.</code><code class="sig-name descname">animations</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; ignite_simple.analarams.AnalysisSettings<a class="reference internal" href="_modules/ignite_simple/analarams.html#animations"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite_simple.analarams.animations" title="Permalink to this definition">¶</a></dt>
<dd><p>Analysis output that uses text, images, and animations. Animations are
videos which are under 15 seconds for the purpose of this module.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>the animations preset for analysis settings, which produces text,
images, and animations in the output.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="#ignite_simple.analarams.AnalysisSettings" title="ignite_simple.analarams.AnalysisSettings">AnalysisSettings</a></p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="ignite_simple.analarams.animations_draft">
<code class="sig-prename descclassname">ignite_simple.analarams.</code><code class="sig-name descname">animations_draft</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; ignite_simple.analarams.AnalysisSettings<a class="reference internal" href="_modules/ignite_simple/analarams.html#animations_draft"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite_simple.analarams.animations_draft" title="Permalink to this definition">¶</a></dt>
<dd><p>Analysis output that uses text, images, and animations but the
animations are given draft settings (i.e. low-fps and low resolution)
to speed up output. For the purposes of this module, animations are
simply videos under 15 seconds.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>the animations-draft preset for analysis settings, which produces
text, image, and draft-quality animations in the output.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="#ignite_simple.analarams.AnalysisSettings" title="ignite_simple.analarams.AnalysisSettings">AnalysisSettings</a></p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="ignite_simple.analarams.images">
<code class="sig-prename descclassname">ignite_simple.analarams.</code><code class="sig-name descname">images</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; ignite_simple.analarams.AnalysisSettings<a class="reference internal" href="_modules/ignite_simple/analarams.html#images"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite_simple.analarams.images" title="Permalink to this definition">¶</a></dt>
<dd><p>Analysis output that uses text and images only</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>the images preset for analysis settings, which produces text
and image output.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="#ignite_simple.analarams.AnalysisSettings" title="ignite_simple.analarams.AnalysisSettings">AnalysisSettings</a></p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="ignite_simple.analarams.none">
<code class="sig-prename descclassname">ignite_simple.analarams.</code><code class="sig-name descname">none</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; ignite_simple.analarams.AnalysisSettings<a class="reference internal" href="_modules/ignite_simple/analarams.html#none"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite_simple.analarams.none" title="Permalink to this definition">¶</a></dt>
<dd><p>Analysis settings that produce absolutely nothing</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>the none preset for analysis settings, which produces no output</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="#ignite_simple.analarams.AnalysisSettings" title="ignite_simple.analarams.AnalysisSettings">AnalysisSettings</a></p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="ignite_simple.analarams.text">
<code class="sig-prename descclassname">ignite_simple.analarams.</code><code class="sig-name descname">text</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; ignite_simple.analarams.AnalysisSettings<a class="reference internal" href="_modules/ignite_simple/analarams.html#text"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite_simple.analarams.text" title="Permalink to this definition">¶</a></dt>
<dd><p>Analysis output that uses text only</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>the text preset for analysis settings, which produces text
output.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="#ignite_simple.analarams.AnalysisSettings" title="ignite_simple.analarams.AnalysisSettings">AnalysisSettings</a></p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="ignite_simple.analarams.video">
<code class="sig-prename descclassname">ignite_simple.analarams.</code><code class="sig-name descname">video</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; ignite_simple.analarams.AnalysisSettings<a class="reference internal" href="_modules/ignite_simple/analarams.html#video"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite_simple.analarams.video" title="Permalink to this definition">¶</a></dt>
<dd><p>Analysis output that uses text, images, animations, and video</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>the video preset for analysis settings, which produces text,
images, animations, and videos in the output.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="#ignite_simple.analarams.AnalysisSettings" title="ignite_simple.analarams.AnalysisSettings">AnalysisSettings</a></p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="ignite_simple.analarams.video_draft">
<code class="sig-prename descclassname">ignite_simple.analarams.</code><code class="sig-name descname">video_draft</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; ignite_simple.analarams.AnalysisSettings<a class="reference internal" href="_modules/ignite_simple/analarams.html#video_draft"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite_simple.analarams.video_draft" title="Permalink to this definition">¶</a></dt>
<dd><p>Analysis output that uses text, images, animations, and video but the
animations and video(s) are given draft settings (i.e. low-fps and
low-resolution) to speed up output</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>the video-draft preset for analysis settings, which produces
text, images, draft-quality animations, and draft-quality videos in the
output.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="#ignite_simple.analarams.AnalysisSettings" title="ignite_simple.analarams.AnalysisSettings">AnalysisSettings</a></p>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-ignite_simple.hyperparams">
<span id="ignite-simple-hyperparams"></span><h1>ignite_simple.hyperparams<a class="headerlink" href="#module-ignite_simple.hyperparams" title="Permalink to this headline">¶</a></h1>
<p>This module is used to describe the hyperparameter tuning settings and
presets used for training.</p>
<dl class="class">
<dt id="ignite_simple.hyperparams.HyperparameterSettings">
<em class="property">class </em><code class="sig-prename descclassname">ignite_simple.hyperparams.</code><code class="sig-name descname">HyperparameterSettings</code><span class="sig-paren">(</span><em class="sig-param">lr_start: float</em>, <em class="sig-param">lr_end: float</em>, <em class="sig-param">lr_min_inits: int</em>, <em class="sig-param">batch_start: int</em>, <em class="sig-param">batch_end: int</em>, <em class="sig-param">batch_rn_min_inits: int</em>, <em class="sig-param">batch_pts: int</em>, <em class="sig-param">batch_pt_min_inits: int</em>, <em class="sig-param">rescan_lr_after_bs: bool</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ignite_simple/hyperparams.html#HyperparameterSettings"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite_simple.hyperparams.HyperparameterSettings" title="Permalink to this definition">¶</a></dt>
<dd><p>Describes settings for tuning hyperparameters</p>
<dl class="field-list simple">
<dt class="field-odd">Variables</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lr_start</strong> (<em>float</em>) – the smallest learning rate that is checked</p></li>
<li><p><strong>lr_end</strong> (<em>float</em>) – the largest learning rate that is checked</p></li>
<li><p><strong>lr_min_inits</strong> (<em>int</em>) – the minimum number of model initializations that
are averaged together and then smoothed to get the lr-vs-accuracy plot.
Note that when multiple physical cores are available they will be
utilized since this process is well-suited to parallelization</p></li>
<li><p><strong>batch_start</strong> (<em>int</em>) – the smallest batch size that is checked during the
initial reasonableness sweep (a single pass)</p></li>
<li><p><strong>batch_end</strong> (<em>int</em>) – the largest batch size that is checked during the
initial reasonableness sweep (a single pass)</p></li>
<li><p><strong>batch_rn_min_inits</strong> (<em>int</em>) – the minimum number of model initializations
that are averaged together then smoothed to get the batch-vs-accuracy
plot.</p></li>
<li><p><strong>batch_pts</strong> (<em>int</em>) – the number of different batch sizes which are checked,
points sampled from a distribution weighted toward a higher first
derivative of performance. Must be either 0 or greater than 1. If 0, the
batch size corresponding to the greatest increase in accuracy during
the reasonableness sweep is used.</p></li>
<li><p><strong>batch_pt_min_inits</strong> (<em>int</em>) – the minimum number of model initializations
that are combined together via LogSumExp. We use LogSumExp instead of
mean because we care more about the best performance than the most
consistent performance when selecting batch size. If you want more
motivation, we prefer a final accuracy of [0, 1, 1] over 3 trials to
[2/3, 2/3, 2/3] even though the mean is the same</p></li>
<li><p><strong>rescan_lr_after_bs</strong> (<em>bool</em>) – if True, the learning rate is scanned once
more after we tweak the batch size. otherwise, we use the same ratio
of learning rate to batch size as we found in the first sweep.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="ignite_simple.hyperparams.fast">
<code class="sig-prename descclassname">ignite_simple.hyperparams.</code><code class="sig-name descname">fast</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; ignite_simple.hyperparams.HyperparameterSettings<a class="reference internal" href="_modules/ignite_simple/hyperparams.html#fast"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite_simple.hyperparams.fast" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a reasonably fast (in time spent tuning parameters) preset</p>
</dd></dl>

<dl class="function">
<dt id="ignite_simple.hyperparams.fastest">
<code class="sig-prename descclassname">ignite_simple.hyperparams.</code><code class="sig-name descname">fastest</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; ignite_simple.hyperparams.HyperparameterSettings<a class="reference internal" href="_modules/ignite_simple/hyperparams.html#fastest"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite_simple.hyperparams.fastest" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the fastest (in time spent tuning parameters) preset</p>
</dd></dl>

<dl class="function">
<dt id="ignite_simple.hyperparams.slow">
<code class="sig-prename descclassname">ignite_simple.hyperparams.</code><code class="sig-name descname">slow</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; ignite_simple.hyperparams.HyperparameterSettings<a class="reference internal" href="_modules/ignite_simple/hyperparams.html#slow"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite_simple.hyperparams.slow" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a somewhat slow (in time spent tuning parameters) preset</p>
</dd></dl>

<dl class="function">
<dt id="ignite_simple.hyperparams.slowest">
<code class="sig-prename descclassname">ignite_simple.hyperparams.</code><code class="sig-name descname">slowest</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; ignite_simple.hyperparams.HyperparameterSettings<a class="reference internal" href="_modules/ignite_simple/hyperparams.html#slowest"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite_simple.hyperparams.slowest" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the slowest (in time spent tuning parameters) preset</p>
</dd></dl>

</div>
<div class="section" id="module-ignite_simple.trainer">
<span id="ignite-simple-trainer"></span><h1>ignite_simple.trainer<a class="headerlink" href="#module-ignite_simple.trainer" title="Permalink to this headline">¶</a></h1>
<p>This module manages preparing and running the training environment for given
settings.</p>
<dl class="class">
<dt id="ignite_simple.trainer.TrainSettings">
<em class="property">class </em><code class="sig-prename descclassname">ignite_simple.trainer.</code><code class="sig-name descname">TrainSettings</code><span class="sig-paren">(</span><em class="sig-param">accuracy_style: str, model_loader: Tuple[str, str, tuple, dict], loss_loader: Tuple[str, str, tuple, dict], task_loader: Tuple[str, str, tuple, dict], handlers: Tuple[Tuple[str, Tuple[str, str, tuple, dict]]], lr_start: float, lr_end: float, cycle_time_epochs: int, epochs: int</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ignite_simple/trainer.html#TrainSettings"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite_simple.trainer.TrainSettings" title="Permalink to this definition">¶</a></dt>
<dd><p>Describes the settings which ultimately go into a training session. This
is intended to be trivially serializable, in that all attributes are built-
ins that can be json serialized.</p>
<dl class="field-list simple">
<dt class="field-odd">Variables</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>accuracy_style</strong> (<em>str</em>) – <p>one of the following constants:</p>
<ul>
<li><dl class="simple">
<dt>classification</dt><dd><p>labels are integers which correspond to the class,
outputs are one-hot encoded classes</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>multiclass</dt><dd><p>labels are one-hot encoded multi-class labels, outputs are the same</p>
</dd>
</dl>
</li>
<li><dl>
<dt>inv-loss</dt><dd><p>accuracy is not measured and inverse loss is used as the
performance metric instead. For stability, instead of exactly
inverse loss,</p>
<div class="math">
<p><img src="_images/math/5ef9beb093b043cd92526190c668543adb9d71ed.svg" alt="\frac{1}{\text{loss} + 10^{-6}}"/></p>
</div><p>is used.</p>
</dd>
</dl>
</li>
</ul>
</p></li>
<li><p><strong>str</strong><strong>, </strong><strong>tuple</strong><strong>, </strong><strong>dict</strong><strong>] </strong><strong>model_loader</strong> (<em>tuple</em><em>[</em><em>str</em><em>,</em>) – the tuple contains the
module and corresponding attribute name for a function which returns
the nn.Module to train. The module must have the calling convention
<cite>model(inp) -&gt; out</cite>. The next two arguments are the args and keyword
args to the callable respectively.</p></li>
<li><p><strong>str</strong><strong>, </strong><strong>tuple</strong><strong>, </strong><strong>dict</strong><strong>] </strong><strong>loss_loader</strong> (<em>tuple</em><em>[</em><em>str</em><em>,</em>) – the tuple contains the
model and corresponding attribute name for a function which returns
the loss function to minimize.</p></li>
<li><p><strong>str</strong><strong>, </strong><strong>tuple</strong><strong>, </strong><strong>dict</strong><strong>] </strong><strong>task_loader</strong> (<em>tuple</em><em>[</em><em>str</em><em>,</em>) – the tuple contains the
module and corresponding attribute name for a function which returns
<code class="code docutils literal notranslate"><span class="pre">(train_set,</span> <span class="pre">val_set,</span> <span class="pre">train_loader)</span></code>, each as described in
TrainState. The next two arguments are the args and keyword args
to the callable respectively.</p></li>
<li><p><strong>tuple</strong><strong>[</strong><strong>str</strong><strong>, </strong><strong>str</strong><strong>, </strong><strong>tuple</strong><strong>, </strong><strong>dict</strong><strong>]</strong><strong>]</strong><strong>] </strong><strong>handlers</strong> (<em>tuple</em><em>[</em><em>tuple</em><em>[</em><em>str</em><em>,</em>) – <p>the event
handlers for the engine which will perform training. After the
specified positional arguments, the handlers will be passed the Engine
that is training the model and the TrainState that is in use. The str
associated with each callable is the event that each callable listens
to.</p>
</p></li>
<li><p><strong>lr_start</strong> (<em>float</em>) – the learning rate at the start of each cycle</p></li>
<li><p><strong>lr_end</strong> (<em>float</em>) – the learning rate at the end of each cycle</p></li>
<li><p><strong>cycle_time_epochs</strong> (<em>int</em>) – the number of epochs for the learning rate
scheduler</p></li>
<li><p><strong>epochs</strong> (<em>int</em>) – the number of epochs to train for</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="ignite_simple.trainer.TrainSettings.get_handlers">
<code class="sig-name descname">get_handlers</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; Tuple[Tuple[str, Callable]]<a class="reference internal" href="_modules/ignite_simple/trainer.html#TrainSettings.get_handlers"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite_simple.trainer.TrainSettings.get_handlers" title="Permalink to this definition">¶</a></dt>
<dd><p>This returns handlers except instead of the function descriptions
(module, attribute, args, kwargs), actual callables are provided with
the necessary arguments and keyword arguments already bound.</p>
</dd></dl>

<dl class="method">
<dt id="ignite_simple.trainer.TrainSettings.get_loss_loader">
<code class="sig-name descname">get_loss_loader</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; Callable<a class="reference internal" href="_modules/ignite_simple/trainer.html#TrainSettings.get_loss_loader"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite_simple.trainer.TrainSettings.get_loss_loader" title="Permalink to this definition">¶</a></dt>
<dd><p>Gets the actual loss loader callable, which is defined through
loss_loader. This is a callable which returns the <cite>torch.nn.Module</cite>
that goes from the output of the model to a scalar which should be
minimized.</p>
</dd></dl>

<dl class="method">
<dt id="ignite_simple.trainer.TrainSettings.get_model_loader">
<code class="sig-name descname">get_model_loader</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; Callable<a class="reference internal" href="_modules/ignite_simple/trainer.html#TrainSettings.get_model_loader"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite_simple.trainer.TrainSettings.get_model_loader" title="Permalink to this definition">¶</a></dt>
<dd><p>Gets the actual model loader callable, which is defined through
model_loader. This is a callable which returns the <cite>torch.nn.Module</cite>
to train. The resulting callable already has the required arguments
and keyword arguments bound.</p>
</dd></dl>

<dl class="method">
<dt id="ignite_simple.trainer.TrainSettings.get_task_loader">
<code class="sig-name descname">get_task_loader</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; Callable<a class="reference internal" href="_modules/ignite_simple/trainer.html#TrainSettings.get_task_loader"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite_simple.trainer.TrainSettings.get_task_loader" title="Permalink to this definition">¶</a></dt>
<dd><p>Gets the actual task loader callable, which is defined through
task_loader. This is a callable which returns
<cite>(train_set, val_set, train_loader)</cite>, each as defined in TrainState.
The resulting callable already has the required arguments
and keyword arguments bound.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="ignite_simple.trainer.TrainState">
<em class="property">class </em><code class="sig-prename descclassname">ignite_simple.trainer.</code><code class="sig-name descname">TrainState</code><span class="sig-paren">(</span><em class="sig-param">model: torch.nn.modules.module.Module</em>, <em class="sig-param">train_set: torch.utils.data.dataset.Dataset</em>, <em class="sig-param">val_set: torch.utils.data.dataset.Dataset</em>, <em class="sig-param">train_loader: torch.utils.data.dataloader.DataLoader</em>, <em class="sig-param">optimizer: torch.optim.optimizer.Optimizer</em>, <em class="sig-param">cycle_time_epochs: int</em>, <em class="sig-param">lr_scheduler: ignite.contrib.handlers.param_scheduler.CyclicalScheduler</em>, <em class="sig-param">loss: torch.nn.modules.module.Module</em>, <em class="sig-param">evaluator: ignite.engine.engine.Engine</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ignite_simple/trainer.html#TrainState"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite_simple.trainer.TrainState" title="Permalink to this definition">¶</a></dt>
<dd><p>Describes the state which is passed as the second positional argument to
each event handler, which contains generic information about the training
session that may be useful.</p>
<dl class="field-list simple">
<dt class="field-odd">Variables</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>torch.nn.Module</em>) – the model which is being trained</p></li>
<li><p><strong>train_set</strong> (<em>torch.utils.data.Dataset</em>) – the dataset which is used to
train the model</p></li>
<li><p><strong>val_set</strong> (<em>torch.utils.data.Dataset</em>) – the dataset which is used to
validate the models performance on unseen / held out data.</p></li>
<li><p><strong>train_loader</strong> (<em>torch.utils.data.DataLoader</em>) – the dataloader which is
being used to generate batches from the train set to be passed into the
model. This incorporates the batch size.</p></li>
<li><p><strong>optimizer</strong> (<em>torch.optim.Optimizer</em>) – the optimizer which is used to
update the parameters of the model.</p></li>
<li><p><strong>cycle_time_epochs</strong> (<em>int</em>) – the number of epochs in a complete cycle
of the learning rate, always even.</p></li>
<li><p><strong>lr_scheduler</strong> (<em>ignite.contrib.handlers.param_scheduler.CyclicalScheduler</em>) – the parameter scheduler for the learning rate. Its instance values can
be used to get the learning rate range and length in batches.</p></li>
<li><p><strong>loss</strong> (<em>torch.nn.Module</em>) – the loss function, which accepts
<code class="code docutils literal notranslate"><span class="pre">(input,</span> <span class="pre">target)</span></code> and returns a scalar which is to be minimized.</p></li>
<li><p><strong>evaluator</strong> (<em>ignite.engine.Engine</em>) – the engine which can be used to
gather metrics. Always has a <code class="code docutils literal notranslate"><span class="pre">'loss'</span></code> and <code class="code docutils literal notranslate"><span class="pre">'perf'</span></code> metric, but
may or may not have an <code class="code docutils literal notranslate"><span class="pre">'accuracy'</span></code> metric.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="ignite_simple.trainer.train">
<code class="sig-prename descclassname">ignite_simple.trainer.</code><code class="sig-name descname">train</code><span class="sig-paren">(</span><em class="sig-param">settings: ignite_simple.trainer.TrainSettings</em><span class="sig-paren">)</span> &#x2192; None<a class="reference internal" href="_modules/ignite_simple/trainer.html#train"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite_simple.trainer.train" title="Permalink to this definition">¶</a></dt>
<dd><p>Trains a model with the given settings.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>In order to store anything you will need to use a handler. For example,
a handler for <cite>ignite.engine.Event.COMPLETED</cite> and stores the
model somewhere.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>settings</strong> (<a class="reference internal" href="#ignite_simple.trainer.TrainSettings" title="ignite_simple.trainer.TrainSettings"><em>TrainSettings</em></a>) – The settings to use for training</p>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-ignite_simple.range_finder">
<span id="ignite-simple-range-finder"></span><h1>ignite_simple.range_finder<a class="headerlink" href="#module-ignite_simple.range_finder" title="Permalink to this headline">¶</a></h1>
<p>This module is responsible for finding a good range of values within which
a measure is increasing most rapidly. This works best when the y-values have
already been smoothed.</p>
<dl class="function">
<dt id="ignite_simple.range_finder.find">
<code class="sig-prename descclassname">ignite_simple.range_finder.</code><code class="sig-name descname">find</code><span class="sig-paren">(</span><em class="sig-param">xs: numpy.ndarray</em>, <em class="sig-param">ys: numpy.ndarray</em><span class="sig-paren">)</span> &#x2192; Tuple[float, float]<a class="reference internal" href="_modules/ignite_simple/range_finder.html#find"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite_simple.range_finder.find" title="Permalink to this definition">¶</a></dt>
<dd><p>Finds the range (min, max) of xs over which the derivative of y is
positive and during which we saw the greatest change in x. This requires
that ys is fairly smooth to produce reasonable results.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If ys was smoothed, then this will be biased to producing intervals
right of the true best interval. If the derivative is smoothed instead,
then find_with_derivs will produce an unbiased interval.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs</strong> (<em>np.ndarray</em>) – The x-values, with shape (num_pts,)</p></li>
<li><p><strong>ys</strong> (<em>np.ndarray</em>) – The y-values, with the same shape as the xs</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>(min, max) of xs where the ys increase the quickest</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="ignite_simple.range_finder.find_with_derivs">
<code class="sig-prename descclassname">ignite_simple.range_finder.</code><code class="sig-name descname">find_with_derivs</code><span class="sig-paren">(</span><em class="sig-param">xs: numpy.ndarray</em>, <em class="sig-param">derivs: numpy.ndarray</em><span class="sig-paren">)</span> &#x2192; Tuple[int, int]<a class="reference internal" href="_modules/ignite_simple/range_finder.html#find_with_derivs"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite_simple.range_finder.find_with_derivs" title="Permalink to this definition">¶</a></dt>
<dd><p>Finds the range in derivs wherein the derivative is always
positive. From these intervals, this returns specifically the one with
the greatest integral.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>xs</strong> (<em>np.ndarray</em>) – with shape <cite>(points,)</cite>, the x-values corresponding to
the derivatives</p></li>
<li><p><strong>derivs</strong> (<em>np.ndarray</em>) – with shape <cite>(points,)</cite>, the relevant derivatives</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>the <cite>(min, max)</cite> for the best interval in xs that has positive
derivative in ys. Where multiple such intervals exist, this is the
one with the greatest integral</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="ignite_simple.range_finder.nonzero_intervals">
<code class="sig-prename descclassname">ignite_simple.range_finder.</code><code class="sig-name descname">nonzero_intervals</code><span class="sig-paren">(</span><em class="sig-param">vec: numpy.ndarray</em><span class="sig-paren">)</span> &#x2192; numpy.ndarray<a class="reference internal" href="_modules/ignite_simple/range_finder.html#nonzero_intervals"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite_simple.range_finder.nonzero_intervals" title="Permalink to this definition">¶</a></dt>
<dd><p>Find which intervals in the given vector are non-zero.</p>
<p>Adapted from <a class="reference external" href="https://stackoverflow.com/a/27642744">https://stackoverflow.com/a/27642744</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>vec</strong> (<em>np.ndarray</em>) – the vector to scan for non-zero intervals</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a list [x1, x2, …, xn] such that [xi, xi+1) is a nonzero
interval in vec</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="ignite_simple.range_finder.smooth_window_size">
<code class="sig-prename descclassname">ignite_simple.range_finder.</code><code class="sig-name descname">smooth_window_size</code><span class="sig-paren">(</span><em class="sig-param">npts: int</em><span class="sig-paren">)</span> &#x2192; int<a class="reference internal" href="_modules/ignite_simple/range_finder.html#smooth_window_size"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite_simple.range_finder.smooth_window_size" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the a heuristic for the window size for smoothing an array with
the given number of points. Specifically, this is 1/10 the number of points
or 101, whichever is smaller.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>npts</strong> (<em>int</em>) – the number of data points you have</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>suggested window size for smoothing the data</p>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-ignite_simple.tuner">
<span id="ignite-simple-tuner"></span><h1>ignite_simple.tuner<a class="headerlink" href="#module-ignite_simple.tuner" title="Permalink to this headline">¶</a></h1>
<p>This module is responsible for tuning the learning rate and batch size for
training a module.</p>
<dl class="function">
<dt id="ignite_simple.tuner.tune">
<code class="sig-prename descclassname">ignite_simple.tuner.</code><code class="sig-name descname">tune</code><span class="sig-paren">(</span><em class="sig-param">model_loader: Tuple[str, str, tuple, dict], dataset_loader: Tuple[str, str, tuple, dict], loss_loader: Tuple[str, str, tuple, dict], accuracy_style: str, folder: str, cores: int, settings: ignite_simple.hyperparams.HyperparameterSettings, store_up_to: ignite_simple.analarams.AnalysisSettings, logger: logging.Logger = None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ignite_simple/tuner.html#tune"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite_simple.tuner.tune" title="Permalink to this definition">¶</a></dt>
<dd><p>Finds the optimal learning rate and batch size for the specified model
on the specified dataset trained with the given loss. Stores the following
information:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">folder</span><span class="o">/</span>
    <span class="n">final</span><span class="o">.</span><span class="n">json</span>
        <span class="p">{</span><span class="s1">&#39;lr_start&#39;</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="s1">&#39;lr_end&#39;</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span> <span class="nb">float</span><span class="p">}</span>
    <span class="n">lr_vs_perf</span><span class="o">.</span><span class="n">npz</span>
        <span class="n">lrs</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">[</span><span class="n">number</span> <span class="n">of</span> <span class="n">batches</span><span class="p">]</span>
        <span class="n">perfs</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">[</span><span class="n">trials</span><span class="p">,</span> <span class="n">number</span> <span class="n">of</span> <span class="n">batches</span><span class="p">]</span>
        <span class="n">perf_derivs</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">[</span><span class="n">trials</span><span class="p">,</span> <span class="n">number_of_batches</span><span class="p">]</span>
        <span class="n">smoothed_perf_derivs</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">[</span><span class="n">trials</span><span class="p">,</span> <span class="n">number</span> <span class="n">of</span> <span class="n">batches</span><span class="p">]</span>
        <span class="n">mean_smoothed_perf_derivs</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">[</span><span class="n">number</span> <span class="n">of</span> <span class="n">batches</span><span class="p">]</span>
        <span class="n">lr_range</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
            <span class="nb">min</span><span class="p">,</span> <span class="nb">max</span> <span class="k">for</span> <span class="n">the</span> <span class="n">good</span> <span class="nb">range</span> <span class="n">of</span> <span class="n">learning</span> <span class="n">rates</span>
    <span class="n">bs_vs_perf</span><span class="o">.</span><span class="n">npz</span>  <span class="p">(</span><span class="n">bs</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
        <span class="n">Where</span> <span class="n">a</span> <span class="n">single</span> <span class="n">batch</span> <span class="ow">is</span> <span class="n">tried</span> <span class="n">multiple</span> <span class="n">times</span><span class="p">,</span> <span class="n">we</span> <span class="n">take</span> <span class="n">the</span>
        <span class="n">mean</span> <span class="n">over</span> <span class="n">those</span> <span class="n">times</span> <span class="n">to</span> <span class="n">ensure</span> <span class="n">bss</span> <span class="n">contains</span> <span class="n">only</span> <span class="n">unique</span>
        <span class="n">values</span> <span class="ow">and</span> <span class="n">hence</span> <span class="n">can</span> <span class="n">be</span> <span class="n">treated</span> <span class="n">like</span> <span class="n">lrs</span>

        <span class="n">bss</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">[</span><span class="n">number</span> <span class="n">of</span> <span class="n">batches</span><span class="p">]</span>
        <span class="n">perfs</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">[</span><span class="n">trials</span><span class="p">,</span> <span class="n">number</span> <span class="n">of</span> <span class="n">batches</span><span class="p">]</span>
        <span class="n">perf_derivs</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">[</span><span class="n">trials</span><span class="p">,</span> <span class="n">number_of_batches</span><span class="p">]</span>
        <span class="n">smoothed_perf_derivs</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">[</span><span class="n">trials</span><span class="p">,</span> <span class="n">number</span> <span class="n">of</span> <span class="n">batches</span><span class="p">]</span>
        <span class="n">mean_smoothed_perf_derivs</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">[</span><span class="n">number</span> <span class="n">of</span> <span class="n">batches</span><span class="p">]</span>
        <span class="n">bs_range</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
            <span class="nb">min</span><span class="p">,</span> <span class="nb">max</span> <span class="k">for</span> <span class="n">the</span> <span class="n">good</span> <span class="nb">range</span> <span class="n">of</span> <span class="n">batch</span> <span class="n">sizes</span>
    <span class="n">lr_vs_perf2</span><span class="o">.</span><span class="n">npz</span>
        <span class="n">only</span> <span class="n">stored</span> <span class="k">if</span> <span class="n">settings</span><span class="o">.</span><span class="n">rescan_lr_after_bs</span><span class="o">.</span> <span class="n">looks</span> <span class="n">exactly</span>
        <span class="n">like</span> <span class="n">lr_vs_perf</span><span class="o">.</span><span class="n">npz</span><span class="p">,</span> <span class="k">except</span> <span class="n">these</span> <span class="n">runs</span> <span class="n">are</span> <span class="n">performed</span> <span class="k">with</span>
        <span class="n">the</span> <span class="n">newly</span> <span class="n">selected</span> <span class="n">batch</span> <span class="n">size</span>
    <span class="n">bs_sampled</span><span class="o">.</span><span class="n">npz</span>
        <span class="n">only</span> <span class="n">stored</span> <span class="k">if</span> <span class="n">settings</span><span class="o">.</span><span class="n">batch_pts</span> <span class="o">&gt;</span> <span class="mi">0</span>

        <span class="n">bss</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">[</span><span class="n">num</span> <span class="n">bs</span> <span class="n">attempted</span><span class="p">]</span>
        <span class="n">final</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">[</span><span class="n">num</span> <span class="n">bs</span> <span class="n">attempted</span><span class="p">,</span> <span class="n">trials</span><span class="p">]</span>
            <span class="n">final</span> <span class="n">performance</span> <span class="k">for</span> <span class="n">batch</span> <span class="n">size</span> <span class="n">i</span> <span class="k">for</span> <span class="n">each</span> <span class="n">trial</span>
        <span class="n">lse_final</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">[</span><span class="n">num</span> <span class="n">bs</span> <span class="n">attempted</span><span class="p">]</span>
            <span class="n">final</span> <span class="n">logsumexp</span> <span class="n">performance</span> <span class="k">for</span> <span class="n">each</span> <span class="n">batch</span> <span class="n">size</span><span class="p">,</span> <span class="n">argmax</span>
            <span class="ow">is</span> <span class="n">the</span> <span class="n">selected</span> <span class="n">batch</span> <span class="n">size</span><span class="o">.</span> <span class="n">If</span> <span class="n">you</span> <span class="n">want</span> <span class="n">this</span> <span class="n">to</span> <span class="n">nicely</span>
            <span class="n">be</span> <span class="n">below</span> <span class="n">the</span> <span class="n">maximum</span><span class="p">,</span> <span class="n">subtract</span> <span class="n">log</span><span class="p">(</span><span class="n">trials</span><span class="p">)</span> <span class="ow">and</span> <span class="n">note</span>
            <span class="n">this</span> <span class="n">does</span> <span class="ow">not</span> <span class="n">effect</span> <span class="n">the</span> <span class="n">argmax</span>

        <span class="n">raw_i</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">[</span><span class="n">trials</span><span class="p">,</span> <span class="n">number</span> <span class="n">of</span> <span class="n">batches</span><span class="p">]</span>
            <span class="n">only</span> <span class="k">if</span> <span class="n">store_up_to</span><span class="o">.</span><span class="n">hparam_selection_specific_imgs</span><span class="p">,</span>
            <span class="n">same</span> <span class="k">for</span> <span class="n">the</span> <span class="o">*</span><span class="n">_raw_i</span>

            <span class="n">i</span> <span class="ow">is</span> <span class="n">a</span> <span class="n">sampled</span> <span class="n">batch</span> <span class="n">size</span> <span class="ow">and</span> <span class="n">raw_i</span><span class="p">[</span><span class="n">t</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="ow">is</span> <span class="n">the</span>
            <span class="n">performance</span> <span class="n">of</span> <span class="n">the</span> <span class="n">model</span> <span class="n">after</span> <span class="n">iteration</span> <span class="n">j</span> <span class="k">for</span>
            <span class="n">batch</span> <span class="n">size</span> <span class="n">i</span> <span class="n">on</span> <span class="n">trial</span> <span class="n">t</span><span class="o">.</span>
        <span class="n">smoothed_raw_i</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">[</span><span class="n">trials</span><span class="p">,</span> <span class="n">number</span> <span class="n">of</span> <span class="n">batches</span><span class="p">]</span>
        <span class="n">lse_smoothed_raw_i</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">[</span><span class="n">number</span> <span class="n">of</span> <span class="n">batches</span><span class="p">]</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model_loader</strong> – <p>describes which module and corresponding attribute can
be passed what arguments and keyword arguments to produce the
nn.Module with a random initialization which can be trained</p>
</p></li>
<li><p><strong>dataset_loader</strong> – describes which module and corresponding attribute
can be passed what arguments and keyword arguments to produce the
training dataset and validation dataset.</p></li>
<li><p><strong>loss_loader</strong> – describes which module and corresponding attribute can
be passed what arguments and keyword arguments to produce the nn.Module
that converts (y_pred, y) to a scalar which should be minimized</p></li>
<li><p><strong>folder</strong> – where to save the output to</p></li>
<li><p><strong>cores</strong> – how many cores to use; 1 for just the main process</p></li>
<li><p><strong>settings</strong> – the settings to use to tune the learning rate and batch
size</p></li>
<li><p><strong>store_up_to</strong> – the information stored should be at least what is
required to produce this analysis</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-ignite_simple.utils">
<span id="ignite-simple-utils"></span><h1>ignite_simple.utils<a class="headerlink" href="#module-ignite_simple.utils" title="Permalink to this headline">¶</a></h1>
<p>Utility functions for creating subsets of dataloaders</p>
<dl class="function">
<dt id="ignite_simple.utils.split">
<code class="sig-prename descclassname">ignite_simple.utils.</code><code class="sig-name descname">split</code><span class="sig-paren">(</span><em class="sig-param">full: torch.utils.data.dataset.Dataset</em>, <em class="sig-param">val_perc: float</em><span class="sig-paren">)</span> &#x2192; Tuple[torch.utils.data.dataset.Dataset, torch.utils.data.dataset.Dataset]<a class="reference internal" href="_modules/ignite_simple/utils.html#split"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite_simple.utils.split" title="Permalink to this definition">¶</a></dt>
<dd><p>Splits the given dataset into two datasets, the first of which has
(1 - val_perc) fraction of the data and the other has val_perc fraction
of the data, distributed randomly.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>full</strong> (<em>data.Dataset</em>) – the entire dataset to split into two</p></li>
<li><p><strong>val_perc</strong> (<em>float</em>) – the amount to be broken away from full</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>(train_set, val_set)</p>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-ignite_simple.vary_bs_loader">
<span id="ignite-simple-vary-bs-loader"></span><h1>ignite_simple.vary_bs_loader<a class="headerlink" href="#module-ignite_simple.vary_bs_loader" title="Permalink to this headline">¶</a></h1>
<p>A torch dataloader which varies the batch size between two amounts
over the course of a specified number of epochs of an underlying dataset. The
variation spends more time at lower batch sizes than at higher batch sizes, for
convenience of implementation and to account for the higher stochasticity at
lower batch sizes</p>
<dl class="class">
<dt id="ignite_simple.vary_bs_loader.BatchSizeVaryingDataLoader">
<em class="property">class </em><code class="sig-prename descclassname">ignite_simple.vary_bs_loader.</code><code class="sig-name descname">BatchSizeVaryingDataLoader</code><span class="sig-paren">(</span><em class="sig-param">dataset</em>, <em class="sig-param">start_batch_size</em>, <em class="sig-param">end_batch_size</em>, <em class="sig-param">epochs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/ignite_simple/vary_bs_loader.html#BatchSizeVaryingDataLoader"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite_simple.vary_bs_loader.BatchSizeVaryingDataLoader" title="Permalink to this definition">¶</a></dt>
<dd><p>A dataloader which acts on an underlying dataset, varying the batch size
linearly between two specified amounts over a given period of time. Note
that this redefines one epoch to be the specified amount of time!</p>
<dl class="field-list simple">
<dt class="field-odd">Variables</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dataset</strong> (<em>data.Dataset</em>) – the underlying dataset from which points and
labels are being pulled</p></li>
<li><p><strong>start_batch_size</strong> (<em>int</em>) – the starting batch size</p></li>
<li><p><strong>end_batch_size</strong> (<em>int</em>) – the final batch size</p></li>
<li><p><strong>epochs</strong> (<em>int</em>) – the number of epochs over which the underlying dataset
is iterated over</p></li>
<li><p><strong>last_iter</strong> (<em>iterator</em>) – the last real iterator that was created</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="ignite_simple.vary_bs_loader.BatchSizeVaryingDataLoader.dry_iter">
<code class="sig-name descname">dry_iter</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/ignite_simple/vary_bs_loader.html#BatchSizeVaryingDataLoader.dry_iter"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#ignite_simple.vary_bs_loader.BatchSizeVaryingDataLoader.dry_iter" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates a ‘dry’ iterator which does not actually produce anything
but has the correct length and updates last_batch_size normally</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="indices-and-tables">
<h1>Indices and tables<a class="headerlink" href="#indices-and-tables" title="Permalink to this headline">¶</a></h1>
<ul class="simple">
<li><p><a class="reference internal" href="genindex.html"><span class="std std-ref">Index</span></a></p></li>
<li><p><a class="reference internal" href="py-modindex.html"><span class="std std-ref">Module Index</span></a></p></li>
<li><p><a class="reference internal" href="search.html"><span class="std std-ref">Search Page</span></a></p></li>
</ul>
</div>


           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>